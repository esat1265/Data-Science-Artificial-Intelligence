{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c2a285",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86dd9568",
   "metadata": {},
   "source": [
    "1- Derin ogrenmede Feature Engineering e gerek yok\n",
    "2- Tensorflow kullaniyoruz. Keras- API kullaniyor\n",
    "3- Tensor - Cok boyutlu Matrix, Flow akis demek. Goog;e tarafindan gelistirildi.Rakip Facebook Pytourch\n",
    "4- GPU (Ekran kartlari ile hesap yapmak daha hizli)\n",
    "5- Derin ogrenme insan beyninin ogrenme seklini kopyalar, insan beyni nasil ogrenoyorsa yapay sinir aglari da oyle ogrenoyor\n",
    "6- Noronlar arsinda gidip gelme islemine Epoch denir.\n",
    "7- Her norondan digerine bir agirlik aktarilir(katsayi)\n",
    "8- Aktarma islemine Aktivasyon fonksiyonu karar verir. ReLu, Softmax, Sigmoid\n",
    "9- Resimler cok buyuk oldugu icin parca parca islenir buna batch-size denir\n",
    "10- Resimler uzerinden calisiyorsaniz CNN kullnailir\n",
    "11- Resim , Text, video uretme islemleri LSTM ile yapilir. (Long-Short Time Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2071c1",
   "metadata": {},
   "source": [
    "### Deep Learning ile Makine ogrenmesi 1-Classification 2- Regression 3-Clustering\n",
    "\n",
    "1- Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c805f975",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\utilisateur\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d0ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3047e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential  # Siralama icin\n",
    "from tensorflow.keras.layers import Dense  # Noronlari birbirine bagliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0adbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68264e5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03be9aa6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096642be",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "198de748",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "       'BMI', 'DiabetesPedigreeFunction', 'Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a7de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df[['Outcome']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad0cc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:8]\n",
    "y=df.iloc[:,8]  # Burada kisaca ustteki x,y ayrimini boylede yapabiliriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f56e5b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73fb942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(8,activation='relu')) #8 sutun oldugu icin 8 ile basladik\n",
    "model.add(Dense(12,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) # sonuc evet mi hayir mi oldugu icin 1 ile bitirdik\n",
    "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3232f168",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7578\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7643\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7474\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.7591\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7552\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.7682\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5134 - accuracy: 0.7526\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7383\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7500\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7552\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.7461\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7474\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7474\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7552\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7617\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7422\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7552\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7591\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7513\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5028 - accuracy: 0.7526\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7669\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7617\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7591\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7435\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7513\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.7474\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7513\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7578\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7448\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7487\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7513\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7474\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7578\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7409\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7591\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7487\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7604\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.7565\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7526\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7604\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7526\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.7487\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7565\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7669\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7578\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7643\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7526\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7565\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7591\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7513\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.7513\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7617\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7617\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.7591\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7591\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7617\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7669\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7643\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7565\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7565\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7682\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7539\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.7695\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7695\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7552\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7617\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7630\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7617\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7552\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7734\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7643\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7526\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7513\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7669\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7630\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.7747\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7617\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7539\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7721\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7448\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7604\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7565\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.7578\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7526\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7604\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7513\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.7708\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.7513\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7669\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7604\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7656\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.7500\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.7682\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7760\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7721\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7565\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7643\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7656\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7656\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7578\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7630\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7708\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7643\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7669\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7604\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7656\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7539\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7604\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7500\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.7630\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7604\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7708\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7682\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7656\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7721\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7591\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7695\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7604\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.7565\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7656\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7656\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4824 - accuracy: 0.7656\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.7695\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7604\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7773\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7513\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7656\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7578\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7669\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7682\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7643\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.7656\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.7695\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.7656\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.7721\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7747\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7565\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7656\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7669\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7643\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7682\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7734\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7513\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7630\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.7721\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.7656\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.7669\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207cec49d30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=150,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b07d36d8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd34d2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7773\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d94f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4803036153316498"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31744997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77734375"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "180deb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early stopping - 150 epoch diye yazdik ama ideali 75 ise orada duruyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23b2c976",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.4662 - accuracy: 0.7655 - val_loss: 0.4553 - val_accuracy: 0.8442\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7622 - val_loss: 0.4404 - val_accuracy: 0.7857\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7834 - val_loss: 0.4501 - val_accuracy: 0.8117\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.7801 - val_loss: 0.4502 - val_accuracy: 0.7922\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7736 - val_loss: 0.4725 - val_accuracy: 0.7662\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7752 - val_loss: 0.4672 - val_accuracy: 0.7922\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7801 - val_loss: 0.4647 - val_accuracy: 0.7857\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7704 - val_loss: 0.4798 - val_accuracy: 0.7857\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7818 - val_loss: 0.5262 - val_accuracy: 0.7662\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7736 - val_loss: 0.5019 - val_accuracy: 0.7857\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7752 - val_loss: 0.4945 - val_accuracy: 0.7662\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7704 - val_loss: 0.4787 - val_accuracy: 0.7922\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4523 - accuracy: 0.7704 - val_loss: 0.5174 - val_accuracy: 0.7857\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7736 - val_loss: 0.5220 - val_accuracy: 0.7857\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.7736 - val_loss: 0.4900 - val_accuracy: 0.8117\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7883 - val_loss: 0.4912 - val_accuracy: 0.7987\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7801 - val_loss: 0.5112 - val_accuracy: 0.7662\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7785 - val_loss: 0.5150 - val_accuracy: 0.7727\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7883 - val_loss: 0.4952 - val_accuracy: 0.7987\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7915 - val_loss: 0.5048 - val_accuracy: 0.7857\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7720 - val_loss: 0.5262 - val_accuracy: 0.7727\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7850 - val_loss: 0.5411 - val_accuracy: 0.7857\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7736 - val_loss: 0.5224 - val_accuracy: 0.7727\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7752 - val_loss: 0.5450 - val_accuracy: 0.7532\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7638 - val_loss: 0.5409 - val_accuracy: 0.7922\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7915 - val_loss: 0.5360 - val_accuracy: 0.7792\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4456 - accuracy: 0.7915 - val_loss: 0.5630 - val_accuracy: 0.7857\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7687 - val_loss: 0.6285 - val_accuracy: 0.7468\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7671 - val_loss: 0.5472 - val_accuracy: 0.7987\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7801 - val_loss: 0.5581 - val_accuracy: 0.7727\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7785 - val_loss: 0.5467 - val_accuracy: 0.7727\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7801 - val_loss: 0.5544 - val_accuracy: 0.7662\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7801 - val_loss: 0.5799 - val_accuracy: 0.7468\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.7785 - val_loss: 0.5443 - val_accuracy: 0.7792\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7752 - val_loss: 0.5361 - val_accuracy: 0.7662\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7720 - val_loss: 0.5454 - val_accuracy: 0.7987\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7655 - val_loss: 0.5581 - val_accuracy: 0.7792\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7769 - val_loss: 0.5974 - val_accuracy: 0.7597\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7752 - val_loss: 0.5448 - val_accuracy: 0.7727\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7769 - val_loss: 0.5565 - val_accuracy: 0.7727\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7785 - val_loss: 0.5570 - val_accuracy: 0.8117\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7769 - val_loss: 0.5549 - val_accuracy: 0.7727\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4471 - accuracy: 0.7785 - val_loss: 0.5611 - val_accuracy: 0.7922\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7785 - val_loss: 0.5556 - val_accuracy: 0.7987\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7687 - val_loss: 0.5696 - val_accuracy: 0.7792\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7866 - val_loss: 0.5619 - val_accuracy: 0.7727\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7720 - val_loss: 0.5800 - val_accuracy: 0.7532\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7704 - val_loss: 0.6307 - val_accuracy: 0.7338\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7590 - val_loss: 0.5804 - val_accuracy: 0.7597\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7671 - val_loss: 0.5656 - val_accuracy: 0.7857\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7834 - val_loss: 0.5907 - val_accuracy: 0.7792\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7850 - val_loss: 0.5717 - val_accuracy: 0.7792\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7834 - val_loss: 0.5726 - val_accuracy: 0.7987\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7899 - val_loss: 0.5798 - val_accuracy: 0.7857\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7834 - val_loss: 0.5686 - val_accuracy: 0.7987\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.7736 - val_loss: 0.5728 - val_accuracy: 0.7922\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7752 - val_loss: 0.5861 - val_accuracy: 0.7727\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7818 - val_loss: 0.6057 - val_accuracy: 0.7662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7785 - val_loss: 0.5736 - val_accuracy: 0.7792\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7736 - val_loss: 0.5911 - val_accuracy: 0.7792\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7785 - val_loss: 0.5966 - val_accuracy: 0.7792\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7866 - val_loss: 0.5850 - val_accuracy: 0.7857\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7736 - val_loss: 0.5836 - val_accuracy: 0.7662\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7834 - val_loss: 0.6024 - val_accuracy: 0.7727\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7720 - val_loss: 0.5945 - val_accuracy: 0.7662\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7736 - val_loss: 0.6007 - val_accuracy: 0.7662\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4351 - accuracy: 0.7899 - val_loss: 0.5878 - val_accuracy: 0.7987\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7769 - val_loss: 0.5903 - val_accuracy: 0.7662\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7720 - val_loss: 0.5813 - val_accuracy: 0.7987\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7801 - val_loss: 0.5844 - val_accuracy: 0.7727\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7801 - val_loss: 0.5888 - val_accuracy: 0.7597\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7736 - val_loss: 0.6295 - val_accuracy: 0.7727\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7850 - val_loss: 0.6010 - val_accuracy: 0.7792\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7622 - val_loss: 0.6063 - val_accuracy: 0.7857\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7785 - val_loss: 0.5810 - val_accuracy: 0.8117\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7752 - val_loss: 0.5920 - val_accuracy: 0.7857\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7736 - val_loss: 0.5962 - val_accuracy: 0.7987\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7883 - val_loss: 0.6039 - val_accuracy: 0.7857\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4422 - accuracy: 0.7704 - val_loss: 0.5926 - val_accuracy: 0.7922\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7752 - val_loss: 0.5927 - val_accuracy: 0.7922\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7932 - val_loss: 0.5830 - val_accuracy: 0.7727\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7834 - val_loss: 0.6278 - val_accuracy: 0.7792\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.7622 - val_loss: 0.5908 - val_accuracy: 0.7792\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7720 - val_loss: 0.5894 - val_accuracy: 0.7792\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7671 - val_loss: 0.5713 - val_accuracy: 0.8052\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7687 - val_loss: 0.6044 - val_accuracy: 0.7597\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7752 - val_loss: 0.6210 - val_accuracy: 0.7857\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7769 - val_loss: 0.6180 - val_accuracy: 0.7922\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4357 - accuracy: 0.7785 - val_loss: 0.6126 - val_accuracy: 0.7727\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7638 - val_loss: 0.6165 - val_accuracy: 0.7922\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7720 - val_loss: 0.6304 - val_accuracy: 0.7922\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7964 - val_loss: 0.6011 - val_accuracy: 0.8117\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7769 - val_loss: 0.6178 - val_accuracy: 0.7922\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7752 - val_loss: 0.6336 - val_accuracy: 0.7857\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7736 - val_loss: 0.6627 - val_accuracy: 0.7532\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7720 - val_loss: 0.6329 - val_accuracy: 0.7857\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4374 - accuracy: 0.7818 - val_loss: 0.6230 - val_accuracy: 0.8117\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7720 - val_loss: 0.6547 - val_accuracy: 0.7662\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7883 - val_loss: 0.5999 - val_accuracy: 0.7987\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4562 - accuracy: 0.7720 - val_loss: 0.6062 - val_accuracy: 0.7922\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7606 - val_loss: 0.5978 - val_accuracy: 0.7922\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7785 - val_loss: 0.6472 - val_accuracy: 0.7532\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7850 - val_loss: 0.6301 - val_accuracy: 0.7792\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7883 - val_loss: 0.6256 - val_accuracy: 0.7922\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7818 - val_loss: 0.6516 - val_accuracy: 0.7662\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7704 - val_loss: 0.6291 - val_accuracy: 0.7662\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7915 - val_loss: 0.6409 - val_accuracy: 0.7792\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7720 - val_loss: 0.6202 - val_accuracy: 0.7922\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.7752 - val_loss: 0.6324 - val_accuracy: 0.7662\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7720 - val_loss: 0.6516 - val_accuracy: 0.7727\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7752 - val_loss: 0.6462 - val_accuracy: 0.7662\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.7834 - val_loss: 0.6554 - val_accuracy: 0.8052\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7866 - val_loss: 0.6392 - val_accuracy: 0.7857\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7850 - val_loss: 0.6571 - val_accuracy: 0.7922\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4331 - accuracy: 0.7834 - val_loss: 0.6424 - val_accuracy: 0.7922\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7866 - val_loss: 0.6393 - val_accuracy: 0.7792\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7932 - val_loss: 0.6411 - val_accuracy: 0.7857\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7932 - val_loss: 0.6682 - val_accuracy: 0.7662\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7818 - val_loss: 0.6382 - val_accuracy: 0.7857\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7720 - val_loss: 0.6538 - val_accuracy: 0.7727\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7801 - val_loss: 0.6350 - val_accuracy: 0.7727\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7736 - val_loss: 0.6656 - val_accuracy: 0.8052\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7687 - val_loss: 0.6734 - val_accuracy: 0.7987\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7785 - val_loss: 0.6777 - val_accuracy: 0.7727\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7801 - val_loss: 0.6599 - val_accuracy: 0.8117\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7785 - val_loss: 0.6695 - val_accuracy: 0.7727\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7752 - val_loss: 0.6846 - val_accuracy: 0.7662\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7785 - val_loss: 0.6756 - val_accuracy: 0.7662\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7818 - val_loss: 0.6717 - val_accuracy: 0.7922\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7736 - val_loss: 0.6812 - val_accuracy: 0.7987\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7785 - val_loss: 0.6729 - val_accuracy: 0.7727\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7801 - val_loss: 0.6793 - val_accuracy: 0.7468\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7883 - val_loss: 0.6614 - val_accuracy: 0.8117\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7704 - val_loss: 0.6932 - val_accuracy: 0.7857\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7801 - val_loss: 0.6828 - val_accuracy: 0.7468\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7671 - val_loss: 0.6888 - val_accuracy: 0.7922\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7785 - val_loss: 0.6493 - val_accuracy: 0.8052\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7752 - val_loss: 0.6686 - val_accuracy: 0.7987\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7769 - val_loss: 0.6575 - val_accuracy: 0.7662\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.7866 - val_loss: 0.6762 - val_accuracy: 0.7922\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7752 - val_loss: 0.6646 - val_accuracy: 0.7597\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7736 - val_loss: 0.6768 - val_accuracy: 0.7532\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7769 - val_loss: 0.6656 - val_accuracy: 0.7987\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7834 - val_loss: 0.6878 - val_accuracy: 0.7597\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7850 - val_loss: 0.6628 - val_accuracy: 0.7857\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7899 - val_loss: 0.6667 - val_accuracy: 0.7792\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7785 - val_loss: 0.6793 - val_accuracy: 0.7922\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7866 - val_loss: 0.6981 - val_accuracy: 0.7727\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7752 - val_loss: 0.7088 - val_accuracy: 0.7532\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7932 - val_loss: 0.7206 - val_accuracy: 0.7662\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=150,validation_split=0.20,batch_size=10,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f87f9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "008a2673",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x207cc6175e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='ValAccuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60265db",
   "metadata": {},
   "source": [
    "2-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0e450ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95a48cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_pickle('kc_house.pkl')\n",
    "pd.set_option(\"display.max_columns\",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9d4ae85",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>grade</th>\n",
       "      <th>view</th>\n",
       "      <th>basement</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>floors</th>\n",
       "      <th>age</th>\n",
       "      <th>renovated</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>price</th>\n",
       "      <th>zipcode_98002</th>\n",
       "      <th>zipcode_98003</th>\n",
       "      <th>zipcode_98004</th>\n",
       "      <th>zipcode_98005</th>\n",
       "      <th>zipcode_98006</th>\n",
       "      <th>zipcode_98007</th>\n",
       "      <th>zipcode_98008</th>\n",
       "      <th>zipcode_98010</th>\n",
       "      <th>zipcode_98011</th>\n",
       "      <th>zipcode_98014</th>\n",
       "      <th>zipcode_98019</th>\n",
       "      <th>zipcode_98022</th>\n",
       "      <th>zipcode_98023</th>\n",
       "      <th>zipcode_98024</th>\n",
       "      <th>zipcode_98027</th>\n",
       "      <th>zipcode_98028</th>\n",
       "      <th>zipcode_98029</th>\n",
       "      <th>zipcode_98030</th>\n",
       "      <th>zipcode_98031</th>\n",
       "      <th>zipcode_98032</th>\n",
       "      <th>zipcode_98033</th>\n",
       "      <th>zipcode_98034</th>\n",
       "      <th>zipcode_98038</th>\n",
       "      <th>zipcode_98039</th>\n",
       "      <th>zipcode_98040</th>\n",
       "      <th>zipcode_98042</th>\n",
       "      <th>zipcode_98045</th>\n",
       "      <th>zipcode_98052</th>\n",
       "      <th>zipcode_98053</th>\n",
       "      <th>zipcode_98055</th>\n",
       "      <th>zipcode_98056</th>\n",
       "      <th>zipcode_98058</th>\n",
       "      <th>zipcode_98059</th>\n",
       "      <th>zipcode_98065</th>\n",
       "      <th>zipcode_98070</th>\n",
       "      <th>zipcode_98072</th>\n",
       "      <th>zipcode_98074</th>\n",
       "      <th>zipcode_98075</th>\n",
       "      <th>zipcode_98077</th>\n",
       "      <th>zipcode_98092</th>\n",
       "      <th>zipcode_98102</th>\n",
       "      <th>zipcode_98103</th>\n",
       "      <th>zipcode_98105</th>\n",
       "      <th>zipcode_98106</th>\n",
       "      <th>zipcode_98107</th>\n",
       "      <th>zipcode_98108</th>\n",
       "      <th>zipcode_98109</th>\n",
       "      <th>zipcode_98112</th>\n",
       "      <th>zipcode_98115</th>\n",
       "      <th>zipcode_98116</th>\n",
       "      <th>zipcode_98117</th>\n",
       "      <th>zipcode_98118</th>\n",
       "      <th>zipcode_98119</th>\n",
       "      <th>zipcode_98122</th>\n",
       "      <th>zipcode_98125</th>\n",
       "      <th>zipcode_98126</th>\n",
       "      <th>zipcode_98133</th>\n",
       "      <th>zipcode_98136</th>\n",
       "      <th>zipcode_98144</th>\n",
       "      <th>zipcode_98146</th>\n",
       "      <th>zipcode_98148</th>\n",
       "      <th>zipcode_98155</th>\n",
       "      <th>zipcode_98166</th>\n",
       "      <th>zipcode_98168</th>\n",
       "      <th>zipcode_98177</th>\n",
       "      <th>zipcode_98178</th>\n",
       "      <th>zipcode_98188</th>\n",
       "      <th>zipcode_98198</th>\n",
       "      <th>zipcode_98199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1180</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1180</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5.0625</td>\n",
       "      <td>2570</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2170</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>770</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>770</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>1960</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1050</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>1680</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bedrooms  bathrooms  sqft_living  grade  view  basement  waterfront  \\\n",
       "0         9     1.0000         1180      7     0         0           0   \n",
       "1         9     5.0625         2570      7     0         1           0   \n",
       "2         4     1.0000          770      6     0         0           0   \n",
       "3        16     9.0000         1960      7     0         1           0   \n",
       "4         9     4.0000         1680      8     0         0           0   \n",
       "\n",
       "   floors  age  renovated  condition  sqft_above     price  zipcode_98002  \\\n",
       "0     1.0   65          0          3        1180  221900.0              0   \n",
       "1     2.0   69          1          3        2170  538000.0              0   \n",
       "2     1.0   87          0          3         770  180000.0              0   \n",
       "3     1.0   55          0          5        1050  604000.0              0   \n",
       "4     1.0   33          0          3        1680  510000.0              0   \n",
       "\n",
       "   zipcode_98003  zipcode_98004  zipcode_98005  zipcode_98006  zipcode_98007  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98008  zipcode_98010  zipcode_98011  zipcode_98014  zipcode_98019  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98022  zipcode_98023  zipcode_98024  zipcode_98027  zipcode_98028  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              1   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98029  zipcode_98030  zipcode_98031  zipcode_98032  zipcode_98033  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98034  zipcode_98038  zipcode_98039  zipcode_98040  zipcode_98042  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98045  zipcode_98052  zipcode_98053  zipcode_98055  zipcode_98056  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98058  zipcode_98059  zipcode_98065  zipcode_98070  zipcode_98072  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98074  zipcode_98075  zipcode_98077  zipcode_98092  zipcode_98102  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              1              0              0              0              0   \n",
       "\n",
       "   zipcode_98103  zipcode_98105  zipcode_98106  zipcode_98107  zipcode_98108  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98109  zipcode_98112  zipcode_98115  zipcode_98116  zipcode_98117  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98118  zipcode_98119  zipcode_98122  zipcode_98125  zipcode_98126  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98133  zipcode_98136  zipcode_98144  zipcode_98146  zipcode_98148  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98155  zipcode_98166  zipcode_98168  zipcode_98177  zipcode_98178  \\\n",
       "0              0              0              0              0              1   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   zipcode_98188  zipcode_98198  zipcode_98199  \n",
       "0              0              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              0              0              0  \n",
       "4              0              0              0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93efc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('price',axis=1)\n",
    "y=df[[\"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e48ec38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0838fb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5efbfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "10a69003",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(19,activation='relu')) \n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"Adam\",loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3bd750f5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "119/119 [==============================] - 2s 6ms/step - loss: 261887721472.0000 - val_loss: 184450138112.0000\n",
      "Epoch 2/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 54309625856.0000 - val_loss: 32792805376.0000\n",
      "Epoch 3/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 32233631744.0000 - val_loss: 32449263616.0000\n",
      "Epoch 4/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31898097664.0000 - val_loss: 32101201920.0000\n",
      "Epoch 5/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 31526486016.0000 - val_loss: 31744624640.0000\n",
      "Epoch 6/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 31157129216.0000 - val_loss: 31408527360.0000\n",
      "Epoch 7/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 30759587840.0000 - val_loss: 31076098048.0000\n",
      "Epoch 8/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 30409873408.0000 - val_loss: 30661148672.0000\n",
      "Epoch 9/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 30037460992.0000 - val_loss: 30319187968.0000\n",
      "Epoch 10/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 29723449344.0000 - val_loss: 30008526848.0000\n",
      "Epoch 11/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 29404411904.0000 - val_loss: 29722292224.0000\n",
      "Epoch 12/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 29145317376.0000 - val_loss: 29558710272.0000\n",
      "Epoch 13/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28898721792.0000 - val_loss: 29292468224.0000\n",
      "Epoch 14/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28748689408.0000 - val_loss: 29160943616.0000\n",
      "Epoch 15/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28611493888.0000 - val_loss: 29045256192.0000\n",
      "Epoch 16/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28439390208.0000 - val_loss: 28922390528.0000\n",
      "Epoch 17/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28373420032.0000 - val_loss: 28990617600.0000\n",
      "Epoch 18/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28284323840.0000 - val_loss: 28768720896.0000\n",
      "Epoch 19/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 28187846656.0000 - val_loss: 28760772608.0000\n",
      "Epoch 20/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 28105476096.0000 - val_loss: 28612227072.0000\n",
      "Epoch 21/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 28020457472.0000 - val_loss: 28534687744.0000\n",
      "Epoch 22/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 27930109952.0000 - val_loss: 28573272064.0000\n",
      "Epoch 23/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27902582784.0000 - val_loss: 28564101120.0000\n",
      "Epoch 24/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27834949632.0000 - val_loss: 28431081472.0000\n",
      "Epoch 25/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27778441216.0000 - val_loss: 28337477632.0000\n",
      "Epoch 26/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27763728384.0000 - val_loss: 28294866944.0000\n",
      "Epoch 27/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27695003648.0000 - val_loss: 28249612288.0000\n",
      "Epoch 28/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27662999552.0000 - val_loss: 28297920512.0000\n",
      "Epoch 29/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27616577536.0000 - val_loss: 28196618240.0000\n",
      "Epoch 30/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27552436224.0000 - val_loss: 28116197376.0000\n",
      "Epoch 31/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27544760320.0000 - val_loss: 28109004800.0000\n",
      "Epoch 32/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27435130880.0000 - val_loss: 28082579456.0000\n",
      "Epoch 33/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27473897472.0000 - val_loss: 28008216576.0000\n",
      "Epoch 34/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27350908928.0000 - val_loss: 27962898432.0000\n",
      "Epoch 35/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27288958976.0000 - val_loss: 27890374656.0000\n",
      "Epoch 36/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 27234334720.0000 - val_loss: 27823753216.0000\n",
      "Epoch 37/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27227674624.0000 - val_loss: 27916582912.0000\n",
      "Epoch 38/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27118282752.0000 - val_loss: 27793772544.0000\n",
      "Epoch 39/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 27073241088.0000 - val_loss: 27647754240.0000\n",
      "Epoch 40/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 27031099392.0000 - val_loss: 27614676992.0000\n",
      "Epoch 41/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 26938304512.0000 - val_loss: 27539818496.0000\n",
      "Epoch 42/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26866190336.0000 - val_loss: 27447582720.0000\n",
      "Epoch 43/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26746218496.0000 - val_loss: 27399804928.0000\n",
      "Epoch 44/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 26726658048.0000 - val_loss: 27440226304.0000\n",
      "Epoch 45/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 26676234240.0000 - val_loss: 27196178432.0000\n",
      "Epoch 46/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26584303616.0000 - val_loss: 27119740928.0000\n",
      "Epoch 47/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26460114944.0000 - val_loss: 27005626368.0000\n",
      "Epoch 48/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 26366564352.0000 - val_loss: 26896424960.0000\n",
      "Epoch 49/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26215692288.0000 - val_loss: 26803081216.0000\n",
      "Epoch 50/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 26095376384.0000 - val_loss: 26659436544.0000\n",
      "Epoch 51/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25981014016.0000 - val_loss: 26840881152.0000\n",
      "Epoch 52/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 25825959936.0000 - val_loss: 26424922112.0000\n",
      "Epoch 53/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 25659994112.0000 - val_loss: 26186426368.0000\n",
      "Epoch 54/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25434660864.0000 - val_loss: 26517161984.0000\n",
      "Epoch 55/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25310318592.0000 - val_loss: 26036201472.0000\n",
      "Epoch 56/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 25050490880.0000 - val_loss: 25534846976.0000\n",
      "Epoch 57/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 24802355200.0000 - val_loss: 25323534336.0000\n",
      "Epoch 58/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24556427264.0000 - val_loss: 25111177216.0000\n",
      "Epoch 59/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 24180127744.0000 - val_loss: 24594010112.0000\n",
      "Epoch 60/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 23721271296.0000 - val_loss: 24258564096.0000\n",
      "Epoch 61/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 23291711488.0000 - val_loss: 23854829568.0000\n",
      "Epoch 62/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 22733578240.0000 - val_loss: 23152932864.0000\n",
      "Epoch 63/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 22281682944.0000 - val_loss: 22517180416.0000\n",
      "Epoch 64/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 21510971392.0000 - val_loss: 22086205440.0000\n",
      "Epoch 65/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 20940425216.0000 - val_loss: 21260603392.0000\n",
      "Epoch 66/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 20237922304.0000 - val_loss: 20634877952.0000\n",
      "Epoch 67/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 1s 5ms/step - loss: 19868420096.0000 - val_loss: 20277516288.0000\n",
      "Epoch 68/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 19339288576.0000 - val_loss: 20152551424.0000\n",
      "Epoch 69/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 19156531200.0000 - val_loss: 19520684032.0000\n",
      "Epoch 70/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18757814272.0000 - val_loss: 19629158400.0000\n",
      "Epoch 71/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 18620350464.0000 - val_loss: 19556628480.0000\n",
      "Epoch 72/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18291689472.0000 - val_loss: 19121661952.0000\n",
      "Epoch 73/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 18039189504.0000 - val_loss: 18604597248.0000\n",
      "Epoch 74/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 17700712448.0000 - val_loss: 18617243648.0000\n",
      "Epoch 75/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17556664320.0000 - val_loss: 18113720320.0000\n",
      "Epoch 76/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 17286699008.0000 - val_loss: 18074236928.0000\n",
      "Epoch 77/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16975184896.0000 - val_loss: 17713778688.0000\n",
      "Epoch 78/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16821210112.0000 - val_loss: 17520742400.0000\n",
      "Epoch 79/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16678483968.0000 - val_loss: 17786710016.0000\n",
      "Epoch 80/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 16553501696.0000 - val_loss: 17042115584.0000\n",
      "Epoch 81/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 16017139712.0000 - val_loss: 16931430400.0000\n",
      "Epoch 82/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15984075776.0000 - val_loss: 17307824128.0000\n",
      "Epoch 83/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 15677640704.0000 - val_loss: 16403352576.0000\n",
      "Epoch 84/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15442593792.0000 - val_loss: 16500946944.0000\n",
      "Epoch 85/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15440415744.0000 - val_loss: 16061498368.0000\n",
      "Epoch 86/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 15078730752.0000 - val_loss: 16014535680.0000\n",
      "Epoch 87/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14848331776.0000 - val_loss: 15643401216.0000\n",
      "Epoch 88/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14629313536.0000 - val_loss: 15541087232.0000\n",
      "Epoch 89/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14492040192.0000 - val_loss: 15262199808.0000\n",
      "Epoch 90/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14238345216.0000 - val_loss: 15165703168.0000\n",
      "Epoch 91/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 14087484416.0000 - val_loss: 14921779200.0000\n",
      "Epoch 92/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13941390336.0000 - val_loss: 14792756224.0000\n",
      "Epoch 93/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13827424256.0000 - val_loss: 14448893952.0000\n",
      "Epoch 94/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13514095616.0000 - val_loss: 14591927296.0000\n",
      "Epoch 95/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13385013248.0000 - val_loss: 14117894144.0000\n",
      "Epoch 96/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 13409188864.0000 - val_loss: 14122640384.0000\n",
      "Epoch 97/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12997019648.0000 - val_loss: 14082618368.0000\n",
      "Epoch 98/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12885579776.0000 - val_loss: 13611582464.0000\n",
      "Epoch 99/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12722453504.0000 - val_loss: 14401985536.0000\n",
      "Epoch 100/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12612046848.0000 - val_loss: 13874233344.0000\n",
      "Epoch 101/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12433396736.0000 - val_loss: 13210094592.0000\n",
      "Epoch 102/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12251350016.0000 - val_loss: 13104520192.0000\n",
      "Epoch 103/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12224776192.0000 - val_loss: 13604578304.0000\n",
      "Epoch 104/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12066098176.0000 - val_loss: 13167927296.0000\n",
      "Epoch 105/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 12045712384.0000 - val_loss: 12780847104.0000\n",
      "Epoch 106/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11944448000.0000 - val_loss: 12733699072.0000\n",
      "Epoch 107/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11775459328.0000 - val_loss: 12583778304.0000\n",
      "Epoch 108/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11759672320.0000 - val_loss: 12485018624.0000\n",
      "Epoch 109/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11862224896.0000 - val_loss: 13272046592.0000\n",
      "Epoch 110/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11679195136.0000 - val_loss: 12826626048.0000\n",
      "Epoch 111/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11484374016.0000 - val_loss: 12259726336.0000\n",
      "Epoch 112/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11381399552.0000 - val_loss: 12392987648.0000\n",
      "Epoch 113/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11358166016.0000 - val_loss: 12106758144.0000\n",
      "Epoch 114/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11353055232.0000 - val_loss: 12098769920.0000\n",
      "Epoch 115/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11229756416.0000 - val_loss: 11983603712.0000\n",
      "Epoch 116/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11328849920.0000 - val_loss: 12029080576.0000\n",
      "Epoch 117/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 11109352448.0000 - val_loss: 12029806592.0000\n",
      "Epoch 118/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 11033262080.0000 - val_loss: 11818137600.0000\n",
      "Epoch 119/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10974735360.0000 - val_loss: 11781345280.0000\n",
      "Epoch 120/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11056014336.0000 - val_loss: 11704012800.0000\n",
      "Epoch 121/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10918018048.0000 - val_loss: 11639662592.0000\n",
      "Epoch 122/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11195777024.0000 - val_loss: 11647499264.0000\n",
      "Epoch 123/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 11041636352.0000 - val_loss: 13125186560.0000\n",
      "Epoch 124/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10846478336.0000 - val_loss: 11564404736.0000\n",
      "Epoch 125/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10823775232.0000 - val_loss: 11473385472.0000\n",
      "Epoch 126/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10743803904.0000 - val_loss: 11837727744.0000\n",
      "Epoch 127/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10882220032.0000 - val_loss: 11386899456.0000\n",
      "Epoch 128/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10720386048.0000 - val_loss: 12601128960.0000\n",
      "Epoch 129/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10699862016.0000 - val_loss: 11386163200.0000\n",
      "Epoch 130/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10510638080.0000 - val_loss: 11763212288.0000\n",
      "Epoch 131/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10529481728.0000 - val_loss: 11285597184.0000\n",
      "Epoch 132/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10465651712.0000 - val_loss: 11199893504.0000\n",
      "Epoch 133/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 10461003776.0000 - val_loss: 11183641600.0000\n",
      "Epoch 134/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10521111552.0000 - val_loss: 11243698176.0000\n",
      "Epoch 135/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10439970816.0000 - val_loss: 11195230208.0000\n",
      "Epoch 136/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10399038464.0000 - val_loss: 11069440000.0000\n",
      "Epoch 137/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10444747776.0000 - val_loss: 11024436224.0000\n",
      "Epoch 138/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10394065920.0000 - val_loss: 11079311360.0000\n",
      "Epoch 139/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10275321856.0000 - val_loss: 11499261952.0000\n",
      "Epoch 140/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10483096576.0000 - val_loss: 12562976768.0000\n",
      "Epoch 141/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10355197952.0000 - val_loss: 10939966464.0000\n",
      "Epoch 142/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10238609408.0000 - val_loss: 11998472192.0000\n",
      "Epoch 143/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10222078976.0000 - val_loss: 10871172096.0000\n",
      "Epoch 144/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10411128832.0000 - val_loss: 12118545408.0000\n",
      "Epoch 145/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10162832384.0000 - val_loss: 10804007936.0000\n",
      "Epoch 146/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10260005888.0000 - val_loss: 10761195520.0000\n",
      "Epoch 147/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10121882624.0000 - val_loss: 10946089984.0000\n",
      "Epoch 148/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10283368448.0000 - val_loss: 10819155968.0000\n",
      "Epoch 149/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9993289728.0000 - val_loss: 10672840704.0000\n",
      "Epoch 150/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10064251904.0000 - val_loss: 10886731776.0000\n",
      "Epoch 151/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10055387136.0000 - val_loss: 10724829184.0000\n",
      "Epoch 152/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10003764224.0000 - val_loss: 10633120768.0000\n",
      "Epoch 153/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 10100030464.0000 - val_loss: 10632443904.0000\n",
      "Epoch 154/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9981316096.0000 - val_loss: 10554118144.0000\n",
      "Epoch 155/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9922920448.0000 - val_loss: 10533177344.0000\n",
      "Epoch 156/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10030539776.0000 - val_loss: 11226781696.0000\n",
      "Epoch 157/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9912241152.0000 - val_loss: 10499660800.0000\n",
      "Epoch 158/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10014838784.0000 - val_loss: 11049345024.0000\n",
      "Epoch 159/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9806133248.0000 - val_loss: 10569496576.0000\n",
      "Epoch 160/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9871737856.0000 - val_loss: 10416833536.0000\n",
      "Epoch 161/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9822720000.0000 - val_loss: 10630105088.0000\n",
      "Epoch 162/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9951250432.0000 - val_loss: 10386944000.0000\n",
      "Epoch 163/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 10000073728.0000 - val_loss: 11007261696.0000\n",
      "Epoch 164/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9645290496.0000 - val_loss: 10687959040.0000\n",
      "Epoch 165/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9794995200.0000 - val_loss: 10529052672.0000\n",
      "Epoch 166/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9728364544.0000 - val_loss: 10650888192.0000\n",
      "Epoch 167/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9658297344.0000 - val_loss: 10244419584.0000\n",
      "Epoch 168/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9804718080.0000 - val_loss: 10388973568.0000\n",
      "Epoch 169/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9701016576.0000 - val_loss: 10271056896.0000\n",
      "Epoch 170/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9683286016.0000 - val_loss: 10187287552.0000\n",
      "Epoch 171/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9649124352.0000 - val_loss: 10172389376.0000\n",
      "Epoch 172/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9628623872.0000 - val_loss: 10271534080.0000\n",
      "Epoch 173/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9656204288.0000 - val_loss: 11256219648.0000\n",
      "Epoch 174/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9586266112.0000 - val_loss: 10161831936.0000\n",
      "Epoch 175/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9599901696.0000 - val_loss: 10138102784.0000\n",
      "Epoch 176/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9468618752.0000 - val_loss: 11098204160.0000\n",
      "Epoch 177/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9478819840.0000 - val_loss: 10153494528.0000\n",
      "Epoch 178/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9491744768.0000 - val_loss: 10259791872.0000\n",
      "Epoch 179/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9467958272.0000 - val_loss: 10123267072.0000\n",
      "Epoch 180/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9684962304.0000 - val_loss: 10076736512.0000\n",
      "Epoch 181/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9427946496.0000 - val_loss: 10010534912.0000\n",
      "Epoch 182/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9403410432.0000 - val_loss: 9973151744.0000\n",
      "Epoch 183/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9378650112.0000 - val_loss: 9992331264.0000\n",
      "Epoch 184/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9366833152.0000 - val_loss: 9950205952.0000\n",
      "Epoch 185/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9442073600.0000 - val_loss: 10193586176.0000\n",
      "Epoch 186/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9337834496.0000 - val_loss: 9930831872.0000\n",
      "Epoch 187/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9374455808.0000 - val_loss: 9938812928.0000\n",
      "Epoch 188/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9341617152.0000 - val_loss: 9984458752.0000\n",
      "Epoch 189/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9347193856.0000 - val_loss: 9860774912.0000\n",
      "Epoch 190/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9376392192.0000 - val_loss: 10467100672.0000\n",
      "Epoch 191/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9280175104.0000 - val_loss: 10142914560.0000\n",
      "Epoch 192/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9487570944.0000 - val_loss: 9892491264.0000\n",
      "Epoch 193/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9275468800.0000 - val_loss: 9803630592.0000\n",
      "Epoch 194/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9196301312.0000 - val_loss: 10331291648.0000\n",
      "Epoch 195/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9223421952.0000 - val_loss: 9779929088.0000\n",
      "Epoch 196/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9161406464.0000 - val_loss: 9834305536.0000\n",
      "Epoch 197/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9305412608.0000 - val_loss: 9998697472.0000\n",
      "Epoch 198/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9347954688.0000 - val_loss: 9954867200.0000\n",
      "Epoch 199/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 9397509120.0000 - val_loss: 10407196672.0000\n",
      "Epoch 200/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9340099584.0000 - val_loss: 10611730432.0000\n",
      "Epoch 201/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9160885248.0000 - val_loss: 9810298880.0000\n",
      "Epoch 202/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9079717888.0000 - val_loss: 9731722240.0000\n",
      "Epoch 203/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9078592512.0000 - val_loss: 9671209984.0000\n",
      "Epoch 204/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9081336832.0000 - val_loss: 9761860608.0000\n",
      "Epoch 205/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9171963904.0000 - val_loss: 9679043584.0000\n",
      "Epoch 206/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9170018304.0000 - val_loss: 9646048256.0000\n",
      "Epoch 207/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9108401152.0000 - val_loss: 9643529216.0000\n",
      "Epoch 208/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9040587776.0000 - val_loss: 9600192512.0000\n",
      "Epoch 209/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9014263808.0000 - val_loss: 9737324544.0000\n",
      "Epoch 210/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9059191808.0000 - val_loss: 9579361280.0000\n",
      "Epoch 211/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9185774592.0000 - val_loss: 9641049088.0000\n",
      "Epoch 212/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9140029440.0000 - val_loss: 9632322560.0000\n",
      "Epoch 213/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9057190912.0000 - val_loss: 9522504704.0000\n",
      "Epoch 214/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9015236608.0000 - val_loss: 9591478272.0000\n",
      "Epoch 215/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9185564672.0000 - val_loss: 9801745408.0000\n",
      "Epoch 216/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8919124992.0000 - val_loss: 10352083968.0000\n",
      "Epoch 217/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8959127552.0000 - val_loss: 9891088384.0000\n",
      "Epoch 218/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8958687232.0000 - val_loss: 9512920064.0000\n",
      "Epoch 219/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9017095168.0000 - val_loss: 10060223488.0000\n",
      "Epoch 220/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9037833216.0000 - val_loss: 9597367296.0000\n",
      "Epoch 221/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9012973568.0000 - val_loss: 9665810432.0000\n",
      "Epoch 222/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9121284096.0000 - val_loss: 9499701248.0000\n",
      "Epoch 223/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9041813504.0000 - val_loss: 9521617920.0000\n",
      "Epoch 224/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8926598144.0000 - val_loss: 9416307712.0000\n",
      "Epoch 225/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8990475264.0000 - val_loss: 9821789184.0000\n",
      "Epoch 226/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8951831552.0000 - val_loss: 9434552320.0000\n",
      "Epoch 227/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8855625728.0000 - val_loss: 9385207808.0000\n",
      "Epoch 228/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8961201152.0000 - val_loss: 9728163840.0000\n",
      "Epoch 229/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9264912384.0000 - val_loss: 10174130176.0000\n",
      "Epoch 230/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9042058240.0000 - val_loss: 10649271296.0000\n",
      "Epoch 231/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9003403264.0000 - val_loss: 9474590720.0000\n",
      "Epoch 232/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8849887232.0000 - val_loss: 9568488448.0000\n",
      "Epoch 233/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8889809920.0000 - val_loss: 9426198528.0000\n",
      "Epoch 234/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8798342144.0000 - val_loss: 9331893248.0000\n",
      "Epoch 235/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8742091776.0000 - val_loss: 9424610304.0000\n",
      "Epoch 236/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8760517632.0000 - val_loss: 11248662528.0000\n",
      "Epoch 237/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8907797504.0000 - val_loss: 9352214528.0000\n",
      "Epoch 238/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8825639936.0000 - val_loss: 9423742976.0000\n",
      "Epoch 239/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8849993728.0000 - val_loss: 9291161600.0000\n",
      "Epoch 240/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8797046784.0000 - val_loss: 9290331136.0000\n",
      "Epoch 241/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8693334016.0000 - val_loss: 9810522112.0000\n",
      "Epoch 242/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8948087808.0000 - val_loss: 9594031104.0000\n",
      "Epoch 243/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8835805184.0000 - val_loss: 9252371456.0000\n",
      "Epoch 244/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8766069760.0000 - val_loss: 9305349120.0000\n",
      "Epoch 245/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8895649792.0000 - val_loss: 9408245760.0000\n",
      "Epoch 246/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8761674752.0000 - val_loss: 9633241088.0000\n",
      "Epoch 247/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 9234485248.0000 - val_loss: 10340228096.0000\n",
      "Epoch 248/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 9051185152.0000 - val_loss: 9444891648.0000\n",
      "Epoch 249/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8819408896.0000 - val_loss: 9313184768.0000\n",
      "Epoch 250/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8736237568.0000 - val_loss: 10421931008.0000\n",
      "Epoch 251/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8754898944.0000 - val_loss: 9442302976.0000\n",
      "Epoch 252/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8680034304.0000 - val_loss: 9231557632.0000\n",
      "Epoch 253/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8704122880.0000 - val_loss: 9494377472.0000\n",
      "Epoch 254/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8750358528.0000 - val_loss: 9252232192.0000\n",
      "Epoch 255/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8667591680.0000 - val_loss: 9245467648.0000\n",
      "Epoch 256/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8653852672.0000 - val_loss: 9215683584.0000\n",
      "Epoch 257/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8801387520.0000 - val_loss: 9546840064.0000\n",
      "Epoch 258/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8702327808.0000 - val_loss: 10694082560.0000\n",
      "Epoch 259/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8873566208.0000 - val_loss: 9350979584.0000\n",
      "Epoch 260/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8803375104.0000 - val_loss: 9907769344.0000\n",
      "Epoch 261/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8670819328.0000 - val_loss: 9314311168.0000\n",
      "Epoch 262/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8501619200.0000 - val_loss: 9294560256.0000\n",
      "Epoch 263/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8856353792.0000 - val_loss: 10140271616.0000\n",
      "Epoch 264/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8693540864.0000 - val_loss: 9585315840.0000\n",
      "Epoch 265/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8907190272.0000 - val_loss: 9360117760.0000\n",
      "Epoch 266/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 8692238336.0000 - val_loss: 9224264704.0000\n",
      "Epoch 267/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8577722368.0000 - val_loss: 9111816192.0000\n",
      "Epoch 268/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8674538496.0000 - val_loss: 9196195840.0000\n",
      "Epoch 269/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8559171584.0000 - val_loss: 9139358720.0000\n",
      "Epoch 270/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8566543360.0000 - val_loss: 9263114240.0000\n",
      "Epoch 271/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8711863296.0000 - val_loss: 9676759040.0000\n",
      "Epoch 272/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8899223552.0000 - val_loss: 10263330816.0000\n",
      "Epoch 273/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8628659200.0000 - val_loss: 9315492864.0000\n",
      "Epoch 274/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8557531648.0000 - val_loss: 9232821248.0000\n",
      "Epoch 275/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8741237760.0000 - val_loss: 9114608640.0000\n",
      "Epoch 276/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8533261312.0000 - val_loss: 9143773184.0000\n",
      "Epoch 277/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8607111168.0000 - val_loss: 9094218752.0000\n",
      "Epoch 278/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8877030400.0000 - val_loss: 9288217600.0000\n",
      "Epoch 279/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8799644672.0000 - val_loss: 9099838464.0000\n",
      "Epoch 280/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8503524352.0000 - val_loss: 9576625152.0000\n",
      "Epoch 281/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8693369856.0000 - val_loss: 9192040448.0000\n",
      "Epoch 282/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8526011392.0000 - val_loss: 9564425216.0000\n",
      "Epoch 283/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8602198016.0000 - val_loss: 9203379200.0000\n",
      "Epoch 284/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8588312064.0000 - val_loss: 10001531904.0000\n",
      "Epoch 285/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8810850304.0000 - val_loss: 9232139264.0000\n",
      "Epoch 286/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8647294976.0000 - val_loss: 9644572672.0000\n",
      "Epoch 287/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8581412864.0000 - val_loss: 9459394560.0000\n",
      "Epoch 288/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8655307776.0000 - val_loss: 9286071296.0000\n",
      "Epoch 289/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8549545984.0000 - val_loss: 9385569280.0000\n",
      "Epoch 290/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8586862080.0000 - val_loss: 9219807232.0000\n",
      "Epoch 291/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8702434304.0000 - val_loss: 9244665856.0000\n",
      "Epoch 292/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8504968192.0000 - val_loss: 9044489216.0000\n",
      "Epoch 293/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8452129280.0000 - val_loss: 9024265216.0000\n",
      "Epoch 294/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8578756608.0000 - val_loss: 9021184000.0000\n",
      "Epoch 295/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8539376128.0000 - val_loss: 9116923904.0000\n",
      "Epoch 296/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8654688256.0000 - val_loss: 11442554880.0000\n",
      "Epoch 297/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8829202432.0000 - val_loss: 9560303616.0000\n",
      "Epoch 298/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8508098560.0000 - val_loss: 9242295296.0000\n",
      "Epoch 299/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8470318080.0000 - val_loss: 9055270912.0000\n",
      "Epoch 300/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8450840064.0000 - val_loss: 9129513984.0000\n",
      "Epoch 301/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8538851328.0000 - val_loss: 9041005568.0000\n",
      "Epoch 302/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8533161472.0000 - val_loss: 9151926272.0000\n",
      "Epoch 303/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8440579072.0000 - val_loss: 9236422656.0000\n",
      "Epoch 304/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8526542336.0000 - val_loss: 9112642560.0000\n",
      "Epoch 305/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8569296896.0000 - val_loss: 9203206144.0000\n",
      "Epoch 306/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8464427520.0000 - val_loss: 9157814272.0000\n",
      "Epoch 307/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8418875904.0000 - val_loss: 9083075584.0000\n",
      "Epoch 308/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8364884992.0000 - val_loss: 9143347200.0000\n",
      "Epoch 309/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8422264832.0000 - val_loss: 9528410112.0000\n",
      "Epoch 310/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8647425024.0000 - val_loss: 9309712384.0000\n",
      "Epoch 311/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8681845760.0000 - val_loss: 9249775616.0000\n",
      "Epoch 312/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8431916032.0000 - val_loss: 9105878016.0000\n",
      "Epoch 313/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8704191488.0000 - val_loss: 9154429952.0000\n",
      "Epoch 314/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8700221440.0000 - val_loss: 9073400832.0000\n",
      "Epoch 315/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8492070400.0000 - val_loss: 9579251712.0000\n",
      "Epoch 316/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8388691968.0000 - val_loss: 9339133952.0000\n",
      "Epoch 317/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8445992960.0000 - val_loss: 9046888448.0000\n",
      "Epoch 318/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8457629696.0000 - val_loss: 9336192000.0000\n",
      "Epoch 319/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8445108736.0000 - val_loss: 9391308800.0000\n",
      "Epoch 320/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8470647296.0000 - val_loss: 9097242624.0000\n",
      "Epoch 321/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8541207040.0000 - val_loss: 8933286912.0000\n",
      "Epoch 322/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8445611008.0000 - val_loss: 9142166528.0000\n",
      "Epoch 323/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8391310336.0000 - val_loss: 9647640576.0000\n",
      "Epoch 324/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8519919616.0000 - val_loss: 9090271232.0000\n",
      "Epoch 325/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8384870912.0000 - val_loss: 9042656256.0000\n",
      "Epoch 326/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8410931200.0000 - val_loss: 9879196672.0000\n",
      "Epoch 327/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8615389184.0000 - val_loss: 9289701376.0000\n",
      "Epoch 328/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8333117440.0000 - val_loss: 8927418368.0000\n",
      "Epoch 329/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8443323392.0000 - val_loss: 9213223936.0000\n",
      "Epoch 330/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8350201856.0000 - val_loss: 9457223680.0000\n",
      "Epoch 331/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8460609536.0000 - val_loss: 8986076160.0000\n",
      "Epoch 332/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8329221632.0000 - val_loss: 9517714432.0000\n",
      "Epoch 333/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 8574829056.0000 - val_loss: 9304147968.0000\n",
      "Epoch 334/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8483806720.0000 - val_loss: 9054964736.0000\n",
      "Epoch 335/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8418176000.0000 - val_loss: 9248193536.0000\n",
      "Epoch 336/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8511890432.0000 - val_loss: 8935860224.0000\n",
      "Epoch 337/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8579589120.0000 - val_loss: 8897745920.0000\n",
      "Epoch 338/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8332887552.0000 - val_loss: 8961553408.0000\n",
      "Epoch 339/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8340847104.0000 - val_loss: 8895557632.0000\n",
      "Epoch 340/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8371173376.0000 - val_loss: 9083891712.0000\n",
      "Epoch 341/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8469717504.0000 - val_loss: 9046297600.0000\n",
      "Epoch 342/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8376420352.0000 - val_loss: 8970722304.0000\n",
      "Epoch 343/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8342455808.0000 - val_loss: 8968987648.0000\n",
      "Epoch 344/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8375223808.0000 - val_loss: 8899214336.0000\n",
      "Epoch 345/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8424161792.0000 - val_loss: 9340488704.0000\n",
      "Epoch 346/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8635452416.0000 - val_loss: 8897314816.0000\n",
      "Epoch 347/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8509596672.0000 - val_loss: 8934349824.0000\n",
      "Epoch 348/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8423124480.0000 - val_loss: 8960742400.0000\n",
      "Epoch 349/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8417874432.0000 - val_loss: 9209962496.0000\n",
      "Epoch 350/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8412996096.0000 - val_loss: 8899655680.0000\n",
      "Epoch 351/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8329669120.0000 - val_loss: 8955060224.0000\n",
      "Epoch 352/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8498646528.0000 - val_loss: 8919801856.0000\n",
      "Epoch 353/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8259056128.0000 - val_loss: 8872484864.0000\n",
      "Epoch 354/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8299028992.0000 - val_loss: 8904756224.0000\n",
      "Epoch 355/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8333745664.0000 - val_loss: 8849230848.0000\n",
      "Epoch 356/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8297612288.0000 - val_loss: 9418591232.0000\n",
      "Epoch 357/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8465768960.0000 - val_loss: 8951041024.0000\n",
      "Epoch 358/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8364271616.0000 - val_loss: 9195625472.0000\n",
      "Epoch 359/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8575413248.0000 - val_loss: 8930417664.0000\n",
      "Epoch 360/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8370096640.0000 - val_loss: 8910536704.0000\n",
      "Epoch 361/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8318170112.0000 - val_loss: 8868941824.0000\n",
      "Epoch 362/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8255493120.0000 - val_loss: 9035542528.0000\n",
      "Epoch 363/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8355247616.0000 - val_loss: 8961205248.0000\n",
      "Epoch 364/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8461610496.0000 - val_loss: 8901255168.0000\n",
      "Epoch 365/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8453330432.0000 - val_loss: 9082763264.0000\n",
      "Epoch 366/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8389086720.0000 - val_loss: 8892618752.0000\n",
      "Epoch 367/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8314349056.0000 - val_loss: 8883102720.0000\n",
      "Epoch 368/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8527419904.0000 - val_loss: 8909685760.0000\n",
      "Epoch 369/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8366367232.0000 - val_loss: 9967054848.0000\n",
      "Epoch 370/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8373920768.0000 - val_loss: 9083017216.0000\n",
      "Epoch 371/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8286145024.0000 - val_loss: 8884813824.0000\n",
      "Epoch 372/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8284752896.0000 - val_loss: 8900407296.0000\n",
      "Epoch 373/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8297740800.0000 - val_loss: 8934193152.0000\n",
      "Epoch 374/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8270890496.0000 - val_loss: 8827129856.0000\n",
      "Epoch 375/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8310733824.0000 - val_loss: 10160908288.0000\n",
      "Epoch 376/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8334507008.0000 - val_loss: 8826428416.0000\n",
      "Epoch 377/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8309969408.0000 - val_loss: 8861858816.0000\n",
      "Epoch 378/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8195196416.0000 - val_loss: 8882252800.0000\n",
      "Epoch 379/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8365352960.0000 - val_loss: 9161741312.0000\n",
      "Epoch 380/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8250376192.0000 - val_loss: 8851021824.0000\n",
      "Epoch 381/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8323832832.0000 - val_loss: 9156090880.0000\n",
      "Epoch 382/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8271209472.0000 - val_loss: 8892305408.0000\n",
      "Epoch 383/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8494712320.0000 - val_loss: 8911134720.0000\n",
      "Epoch 384/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8248862208.0000 - val_loss: 9637321728.0000\n",
      "Epoch 385/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8325115904.0000 - val_loss: 8874156032.0000\n",
      "Epoch 386/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8469722624.0000 - val_loss: 9373634560.0000\n",
      "Epoch 387/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8652614656.0000 - val_loss: 8874978304.0000\n",
      "Epoch 388/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8258724864.0000 - val_loss: 9541533696.0000\n",
      "Epoch 389/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8335918080.0000 - val_loss: 8856499200.0000\n",
      "Epoch 390/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8240095744.0000 - val_loss: 9178910720.0000\n",
      "Epoch 391/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8278596096.0000 - val_loss: 9270728704.0000\n",
      "Epoch 392/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8245246976.0000 - val_loss: 9220888576.0000\n",
      "Epoch 393/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8606837760.0000 - val_loss: 8919122944.0000\n",
      "Epoch 394/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8192936960.0000 - val_loss: 9048523776.0000\n",
      "Epoch 395/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8191612416.0000 - val_loss: 8776677376.0000\n",
      "Epoch 396/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8325132800.0000 - val_loss: 9107678208.0000\n",
      "Epoch 397/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8366486528.0000 - val_loss: 8950014976.0000\n",
      "Epoch 398/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8213541888.0000 - val_loss: 11533763584.0000\n",
      "Epoch 399/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8404099584.0000 - val_loss: 9298743296.0000\n",
      "Epoch 400/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 8461286912.0000 - val_loss: 8967419904.0000\n",
      "Epoch 401/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8341145088.0000 - val_loss: 8849585152.0000\n",
      "Epoch 402/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8199979520.0000 - val_loss: 8785929216.0000\n",
      "Epoch 403/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8213120000.0000 - val_loss: 9384910848.0000\n",
      "Epoch 404/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8432163328.0000 - val_loss: 11220259840.0000\n",
      "Epoch 405/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8499121152.0000 - val_loss: 8811185152.0000\n",
      "Epoch 406/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8115766784.0000 - val_loss: 8844310528.0000\n",
      "Epoch 407/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8212044288.0000 - val_loss: 9138665472.0000\n",
      "Epoch 408/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8279027200.0000 - val_loss: 8952389632.0000\n",
      "Epoch 409/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8194307072.0000 - val_loss: 9438844928.0000\n",
      "Epoch 410/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8260405760.0000 - val_loss: 8782136320.0000\n",
      "Epoch 411/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8289900032.0000 - val_loss: 11343724544.0000\n",
      "Epoch 412/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8419358208.0000 - val_loss: 8837226496.0000\n",
      "Epoch 413/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8154062336.0000 - val_loss: 9153644544.0000\n",
      "Epoch 414/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8335668736.0000 - val_loss: 8927918080.0000\n",
      "Epoch 415/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8376289280.0000 - val_loss: 9331934208.0000\n",
      "Epoch 416/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8198506496.0000 - val_loss: 8755055616.0000\n",
      "Epoch 417/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8282339328.0000 - val_loss: 8758364160.0000\n",
      "Epoch 418/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8271010304.0000 - val_loss: 9305771008.0000\n",
      "Epoch 419/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8204049408.0000 - val_loss: 8740687872.0000\n",
      "Epoch 420/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8391623680.0000 - val_loss: 8897838080.0000\n",
      "Epoch 421/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8179474432.0000 - val_loss: 8772440064.0000\n",
      "Epoch 422/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8180491776.0000 - val_loss: 8770553856.0000\n",
      "Epoch 423/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8214340608.0000 - val_loss: 9126994944.0000\n",
      "Epoch 424/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 8251072000.0000 - val_loss: 8748270592.0000\n",
      "Epoch 425/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8504543744.0000 - val_loss: 8909982720.0000\n",
      "Epoch 426/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8207826944.0000 - val_loss: 8806755328.0000\n",
      "Epoch 427/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8104978432.0000 - val_loss: 8984824832.0000\n",
      "Epoch 428/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8195204096.0000 - val_loss: 8771859456.0000\n",
      "Epoch 429/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8110876672.0000 - val_loss: 9313148928.0000\n",
      "Epoch 430/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8310258688.0000 - val_loss: 9765770240.0000\n",
      "Epoch 431/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8249380864.0000 - val_loss: 8979494912.0000\n",
      "Epoch 432/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8116620288.0000 - val_loss: 9642976256.0000\n",
      "Epoch 433/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8375652352.0000 - val_loss: 9510610944.0000\n",
      "Epoch 434/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8303105536.0000 - val_loss: 9560549376.0000\n",
      "Epoch 435/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8216089600.0000 - val_loss: 8962721792.0000\n",
      "Epoch 436/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8146535424.0000 - val_loss: 8803301376.0000\n",
      "Epoch 437/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8402828288.0000 - val_loss: 8960490496.0000\n",
      "Epoch 438/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8109114880.0000 - val_loss: 9376283648.0000\n",
      "Epoch 439/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8109968896.0000 - val_loss: 8776430592.0000\n",
      "Epoch 440/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8245152256.0000 - val_loss: 8701444096.0000\n",
      "Epoch 441/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8152939520.0000 - val_loss: 8899591168.0000\n",
      "Epoch 442/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8199177216.0000 - val_loss: 8787167232.0000\n",
      "Epoch 443/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8165442048.0000 - val_loss: 8743224320.0000\n",
      "Epoch 444/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8185824768.0000 - val_loss: 8819502080.0000\n",
      "Epoch 445/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8137149440.0000 - val_loss: 9079693312.0000\n",
      "Epoch 446/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8148862464.0000 - val_loss: 8821242880.0000\n",
      "Epoch 447/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8322126848.0000 - val_loss: 9528398848.0000\n",
      "Epoch 448/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8160237568.0000 - val_loss: 8755599360.0000\n",
      "Epoch 449/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8288578048.0000 - val_loss: 8732550144.0000\n",
      "Epoch 450/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8218848768.0000 - val_loss: 9092408320.0000\n",
      "Epoch 451/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8112599040.0000 - val_loss: 8749316096.0000\n",
      "Epoch 452/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8162147328.0000 - val_loss: 9102794752.0000\n",
      "Epoch 453/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8070234112.0000 - val_loss: 8719664128.0000\n",
      "Epoch 454/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8136571904.0000 - val_loss: 9741777920.0000\n",
      "Epoch 455/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8144089600.0000 - val_loss: 8723392512.0000\n",
      "Epoch 456/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8340876800.0000 - val_loss: 8797242368.0000\n",
      "Epoch 457/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8172637184.0000 - val_loss: 8680259584.0000\n",
      "Epoch 458/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8122729472.0000 - val_loss: 9474758656.0000\n",
      "Epoch 459/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8240373248.0000 - val_loss: 9017135104.0000\n",
      "Epoch 460/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8477118976.0000 - val_loss: 8774270976.0000\n",
      "Epoch 461/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8220709888.0000 - val_loss: 8796649472.0000\n",
      "Epoch 462/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8101092352.0000 - val_loss: 8850315264.0000\n",
      "Epoch 463/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8101527040.0000 - val_loss: 9070289920.0000\n",
      "Epoch 464/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8113524736.0000 - val_loss: 8707857408.0000\n",
      "Epoch 465/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8144308224.0000 - val_loss: 8861367296.0000\n",
      "Epoch 466/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8091113472.0000 - val_loss: 9360405504.0000\n",
      "Epoch 467/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 8082925056.0000 - val_loss: 8672753664.0000\n",
      "Epoch 468/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8215276032.0000 - val_loss: 8740081664.0000\n",
      "Epoch 469/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8152016384.0000 - val_loss: 8714008576.0000\n",
      "Epoch 470/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8128373760.0000 - val_loss: 8735768576.0000\n",
      "Epoch 471/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8103838720.0000 - val_loss: 8701147136.0000\n",
      "Epoch 472/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8212787712.0000 - val_loss: 9449486336.0000\n",
      "Epoch 473/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8117573632.0000 - val_loss: 8827696128.0000\n",
      "Epoch 474/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8194210304.0000 - val_loss: 8755376128.0000\n",
      "Epoch 475/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8087715328.0000 - val_loss: 8939599872.0000\n",
      "Epoch 476/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8103158272.0000 - val_loss: 8776352768.0000\n",
      "Epoch 477/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8424272384.0000 - val_loss: 8744023040.0000\n",
      "Epoch 478/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8198837248.0000 - val_loss: 8742903808.0000\n",
      "Epoch 479/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8159942656.0000 - val_loss: 8702735360.0000\n",
      "Epoch 480/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8041548800.0000 - val_loss: 8991000576.0000\n",
      "Epoch 481/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8095351808.0000 - val_loss: 8777031680.0000\n",
      "Epoch 482/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8069457920.0000 - val_loss: 8669316096.0000\n",
      "Epoch 483/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8147908096.0000 - val_loss: 8796848128.0000\n",
      "Epoch 484/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8011124736.0000 - val_loss: 9803397120.0000\n",
      "Epoch 485/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8119010304.0000 - val_loss: 8904036352.0000\n",
      "Epoch 486/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8210685440.0000 - val_loss: 8683129856.0000\n",
      "Epoch 487/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8090745344.0000 - val_loss: 8704390144.0000\n",
      "Epoch 488/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8165733888.0000 - val_loss: 8745594880.0000\n",
      "Epoch 489/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8334552064.0000 - val_loss: 9093208064.0000\n",
      "Epoch 490/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8174208000.0000 - val_loss: 9575775232.0000\n",
      "Epoch 491/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8122406400.0000 - val_loss: 9039062016.0000\n",
      "Epoch 492/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8142528000.0000 - val_loss: 8726447104.0000\n",
      "Epoch 493/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8031029248.0000 - val_loss: 8690819072.0000\n",
      "Epoch 494/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8077054464.0000 - val_loss: 9026840576.0000\n",
      "Epoch 495/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8078999040.0000 - val_loss: 8757065728.0000\n",
      "Epoch 496/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8293497344.0000 - val_loss: 9781942272.0000\n",
      "Epoch 497/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8007302656.0000 - val_loss: 8855413760.0000\n",
      "Epoch 498/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8272946176.0000 - val_loss: 8655020032.0000\n",
      "Epoch 499/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8137732096.0000 - val_loss: 8816391168.0000\n",
      "Epoch 500/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8169257984.0000 - val_loss: 8637297664.0000\n",
      "Epoch 501/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8054585856.0000 - val_loss: 8699181056.0000\n",
      "Epoch 502/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8135703040.0000 - val_loss: 10016894976.0000\n",
      "Epoch 503/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8209457664.0000 - val_loss: 8859757568.0000\n",
      "Epoch 504/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8157486592.0000 - val_loss: 9261960192.0000\n",
      "Epoch 505/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8062991872.0000 - val_loss: 8665609216.0000\n",
      "Epoch 506/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8110732800.0000 - val_loss: 8777738240.0000\n",
      "Epoch 507/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8184710656.0000 - val_loss: 9105915904.0000\n",
      "Epoch 508/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8098333184.0000 - val_loss: 9236861952.0000\n",
      "Epoch 509/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8119457792.0000 - val_loss: 8661320704.0000\n",
      "Epoch 510/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8125150720.0000 - val_loss: 8635152384.0000\n",
      "Epoch 511/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8017287680.0000 - val_loss: 8797447168.0000\n",
      "Epoch 512/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8063596544.0000 - val_loss: 8783800320.0000\n",
      "Epoch 513/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8124285952.0000 - val_loss: 8888527872.0000\n",
      "Epoch 514/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8019457536.0000 - val_loss: 8669424640.0000\n",
      "Epoch 515/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8258868224.0000 - val_loss: 9746140160.0000\n",
      "Epoch 516/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8061149184.0000 - val_loss: 9022793728.0000\n",
      "Epoch 517/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8102230016.0000 - val_loss: 8792416256.0000\n",
      "Epoch 518/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8005196288.0000 - val_loss: 8622955520.0000\n",
      "Epoch 519/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8052053504.0000 - val_loss: 8717404160.0000\n",
      "Epoch 520/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 8266205184.0000 - val_loss: 8804120576.0000\n",
      "Epoch 521/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8212944384.0000 - val_loss: 8711915520.0000\n",
      "Epoch 522/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7984872448.0000 - val_loss: 8762450944.0000\n",
      "Epoch 523/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8230350848.0000 - val_loss: 9248601088.0000\n",
      "Epoch 524/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8106851840.0000 - val_loss: 8636686336.0000\n",
      "Epoch 525/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7937347072.0000 - val_loss: 8798371840.0000\n",
      "Epoch 526/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8127504896.0000 - val_loss: 8936885248.0000\n",
      "Epoch 527/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7975370240.0000 - val_loss: 8665402368.0000\n",
      "Epoch 528/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8064743424.0000 - val_loss: 8712894464.0000\n",
      "Epoch 529/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8067231744.0000 - val_loss: 8738016256.0000\n",
      "Epoch 530/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7972295680.0000 - val_loss: 8689135616.0000\n",
      "Epoch 531/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7980308992.0000 - val_loss: 9152794624.0000\n",
      "Epoch 532/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8093892096.0000 - val_loss: 8649225216.0000\n",
      "Epoch 533/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8174145536.0000 - val_loss: 8756045824.0000\n",
      "Epoch 534/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 8030266880.0000 - val_loss: 8858183680.0000\n",
      "Epoch 535/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8230184448.0000 - val_loss: 9684779008.0000\n",
      "Epoch 536/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8043778560.0000 - val_loss: 8674442240.0000\n",
      "Epoch 537/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8193857536.0000 - val_loss: 9175870464.0000\n",
      "Epoch 538/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8436332032.0000 - val_loss: 9997237248.0000\n",
      "Epoch 539/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7966718976.0000 - val_loss: 9235512320.0000\n",
      "Epoch 540/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8149364736.0000 - val_loss: 9166226432.0000\n",
      "Epoch 541/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8073190400.0000 - val_loss: 8678705152.0000\n",
      "Epoch 542/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8038496256.0000 - val_loss: 8590911488.0000\n",
      "Epoch 543/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7952518144.0000 - val_loss: 8932328448.0000\n",
      "Epoch 544/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8068517376.0000 - val_loss: 8790312960.0000\n",
      "Epoch 545/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8038259200.0000 - val_loss: 8740880384.0000\n",
      "Epoch 546/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7943482368.0000 - val_loss: 8933982208.0000\n",
      "Epoch 547/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8176898560.0000 - val_loss: 8651119616.0000\n",
      "Epoch 548/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7982182912.0000 - val_loss: 9038680064.0000\n",
      "Epoch 549/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7961910272.0000 - val_loss: 9120084992.0000\n",
      "Epoch 550/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8067020800.0000 - val_loss: 8816997376.0000\n",
      "Epoch 551/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8127631872.0000 - val_loss: 8842956800.0000\n",
      "Epoch 552/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8026006528.0000 - val_loss: 9494578176.0000\n",
      "Epoch 553/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8107096064.0000 - val_loss: 8732476416.0000\n",
      "Epoch 554/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7917572096.0000 - val_loss: 8830935040.0000\n",
      "Epoch 555/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7984872960.0000 - val_loss: 9260478464.0000\n",
      "Epoch 556/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8236164608.0000 - val_loss: 8781016064.0000\n",
      "Epoch 557/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8247185920.0000 - val_loss: 8555627520.0000\n",
      "Epoch 558/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7988114944.0000 - val_loss: 8933315584.0000\n",
      "Epoch 559/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8003322368.0000 - val_loss: 8559449088.0000\n",
      "Epoch 560/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7893110272.0000 - val_loss: 8612402176.0000\n",
      "Epoch 561/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7901154816.0000 - val_loss: 8722918400.0000\n",
      "Epoch 562/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8074881024.0000 - val_loss: 8577666048.0000\n",
      "Epoch 563/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8013891584.0000 - val_loss: 8808830976.0000\n",
      "Epoch 564/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7963065856.0000 - val_loss: 8770080768.0000\n",
      "Epoch 565/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7976036864.0000 - val_loss: 8686701568.0000\n",
      "Epoch 566/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8043642368.0000 - val_loss: 9753245696.0000\n",
      "Epoch 567/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8036858368.0000 - val_loss: 9692039168.0000\n",
      "Epoch 568/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7975774208.0000 - val_loss: 9896700928.0000\n",
      "Epoch 569/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8298291200.0000 - val_loss: 8563324928.0000\n",
      "Epoch 570/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8036150272.0000 - val_loss: 9021862912.0000\n",
      "Epoch 571/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7905359872.0000 - val_loss: 8774150144.0000\n",
      "Epoch 572/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7993390592.0000 - val_loss: 8613822464.0000\n",
      "Epoch 573/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7930851840.0000 - val_loss: 8580917760.0000\n",
      "Epoch 574/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7884915712.0000 - val_loss: 8662029312.0000\n",
      "Epoch 575/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8057584640.0000 - val_loss: 9684590592.0000\n",
      "Epoch 576/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8055625728.0000 - val_loss: 8686119936.0000\n",
      "Epoch 577/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7978759168.0000 - val_loss: 9152862208.0000\n",
      "Epoch 578/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7997736960.0000 - val_loss: 9464544256.0000\n",
      "Epoch 579/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7993746432.0000 - val_loss: 8763619328.0000\n",
      "Epoch 580/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8066779648.0000 - val_loss: 9274887168.0000\n",
      "Epoch 581/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8052481024.0000 - val_loss: 9279391744.0000\n",
      "Epoch 582/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7946534400.0000 - val_loss: 8578649088.0000\n",
      "Epoch 583/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8021616640.0000 - val_loss: 9159853056.0000\n",
      "Epoch 584/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8073244160.0000 - val_loss: 8801128448.0000\n",
      "Epoch 585/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7925163008.0000 - val_loss: 9271264256.0000\n",
      "Epoch 586/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7977118208.0000 - val_loss: 8533814272.0000\n",
      "Epoch 587/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8208101376.0000 - val_loss: 8895700992.0000\n",
      "Epoch 588/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8361168384.0000 - val_loss: 9287876608.0000\n",
      "Epoch 589/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7955330560.0000 - val_loss: 8856992768.0000\n",
      "Epoch 590/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7992330240.0000 - val_loss: 8561241088.0000\n",
      "Epoch 591/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7959317504.0000 - val_loss: 8580441088.0000\n",
      "Epoch 592/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7882182656.0000 - val_loss: 8795855872.0000\n",
      "Epoch 593/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8076863488.0000 - val_loss: 8731223040.0000\n",
      "Epoch 594/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7953112064.0000 - val_loss: 8986626048.0000\n",
      "Epoch 595/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8131961856.0000 - val_loss: 10128561152.0000\n",
      "Epoch 596/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8030425088.0000 - val_loss: 8588772864.0000\n",
      "Epoch 597/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8012933632.0000 - val_loss: 8597312512.0000\n",
      "Epoch 598/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8137856512.0000 - val_loss: 8707822592.0000\n",
      "Epoch 599/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8127120384.0000 - val_loss: 9085202432.0000\n",
      "Epoch 600/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7840678912.0000 - val_loss: 8630434816.0000\n",
      "Epoch 601/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7907138048.0000 - val_loss: 8552552960.0000\n",
      "Epoch 602/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8003883008.0000 - val_loss: 9018672128.0000\n",
      "Epoch 603/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7886225920.0000 - val_loss: 8696776704.0000\n",
      "Epoch 604/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7909702144.0000 - val_loss: 8604962816.0000\n",
      "Epoch 605/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8014343680.0000 - val_loss: 8866856960.0000\n",
      "Epoch 606/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8084080640.0000 - val_loss: 8599790592.0000\n",
      "Epoch 607/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7914891264.0000 - val_loss: 9048161280.0000\n",
      "Epoch 608/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7981402112.0000 - val_loss: 9578374144.0000\n",
      "Epoch 609/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7966457856.0000 - val_loss: 8587421184.0000\n",
      "Epoch 610/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7944807424.0000 - val_loss: 8688731136.0000\n",
      "Epoch 611/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7980056064.0000 - val_loss: 8527971328.0000\n",
      "Epoch 612/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7948454400.0000 - val_loss: 8582684672.0000\n",
      "Epoch 613/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7980414976.0000 - val_loss: 8821374976.0000\n",
      "Epoch 614/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7901357056.0000 - val_loss: 8865830912.0000\n",
      "Epoch 615/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8039908864.0000 - val_loss: 8549048832.0000\n",
      "Epoch 616/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7956291072.0000 - val_loss: 8663262208.0000\n",
      "Epoch 617/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7906477056.0000 - val_loss: 9340477440.0000\n",
      "Epoch 618/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7844290560.0000 - val_loss: 8646083584.0000\n",
      "Epoch 619/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7908634624.0000 - val_loss: 10074471424.0000\n",
      "Epoch 620/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7901721600.0000 - val_loss: 8991728640.0000\n",
      "Epoch 621/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7883678720.0000 - val_loss: 8983153664.0000\n",
      "Epoch 622/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7964998656.0000 - val_loss: 8546237952.0000\n",
      "Epoch 623/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7895610368.0000 - val_loss: 9047777280.0000\n",
      "Epoch 624/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7772078592.0000 - val_loss: 8501626880.0000\n",
      "Epoch 625/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8375328768.0000 - val_loss: 9341118464.0000\n",
      "Epoch 626/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7959688704.0000 - val_loss: 8586599424.0000\n",
      "Epoch 627/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8093522944.0000 - val_loss: 9144401920.0000\n",
      "Epoch 628/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7998896640.0000 - val_loss: 8674614272.0000\n",
      "Epoch 629/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7966461440.0000 - val_loss: 8577667072.0000\n",
      "Epoch 630/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8026049024.0000 - val_loss: 9052989440.0000\n",
      "Epoch 631/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7946959360.0000 - val_loss: 8641163264.0000\n",
      "Epoch 632/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7913300480.0000 - val_loss: 8741378048.0000\n",
      "Epoch 633/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7939668992.0000 - val_loss: 8755475456.0000\n",
      "Epoch 634/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7834870272.0000 - val_loss: 8513068032.0000\n",
      "Epoch 635/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7914203136.0000 - val_loss: 8554420224.0000\n",
      "Epoch 636/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8036636672.0000 - val_loss: 8972413952.0000\n",
      "Epoch 637/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8196004352.0000 - val_loss: 8574643200.0000\n",
      "Epoch 638/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7856007680.0000 - val_loss: 8558890496.0000\n",
      "Epoch 639/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7890040320.0000 - val_loss: 8854691840.0000\n",
      "Epoch 640/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8000906752.0000 - val_loss: 8563671040.0000\n",
      "Epoch 641/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7984001536.0000 - val_loss: 8587304960.0000\n",
      "Epoch 642/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7800644096.0000 - val_loss: 8800385024.0000\n",
      "Epoch 643/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8106528256.0000 - val_loss: 8535774720.0000\n",
      "Epoch 644/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7929581056.0000 - val_loss: 8505099776.0000\n",
      "Epoch 645/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7789606912.0000 - val_loss: 8528114176.0000\n",
      "Epoch 646/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7921979904.0000 - val_loss: 8821068800.0000\n",
      "Epoch 647/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8048723456.0000 - val_loss: 8770397184.0000\n",
      "Epoch 648/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7945149952.0000 - val_loss: 8760028160.0000\n",
      "Epoch 649/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7843217920.0000 - val_loss: 9309693952.0000\n",
      "Epoch 650/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8065786880.0000 - val_loss: 9279176704.0000\n",
      "Epoch 651/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7999040000.0000 - val_loss: 9392030720.0000\n",
      "Epoch 652/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7901722112.0000 - val_loss: 8478332416.0000\n",
      "Epoch 653/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7996993024.0000 - val_loss: 8976458752.0000\n",
      "Epoch 654/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7808644608.0000 - val_loss: 9251372032.0000\n",
      "Epoch 655/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7841893888.0000 - val_loss: 8572603904.0000\n",
      "Epoch 656/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7856678912.0000 - val_loss: 8924220416.0000\n",
      "Epoch 657/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7859981312.0000 - val_loss: 8524905472.0000\n",
      "Epoch 658/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7885654528.0000 - val_loss: 8470789120.0000\n",
      "Epoch 659/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7965324800.0000 - val_loss: 8565662208.0000\n",
      "Epoch 660/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7933221888.0000 - val_loss: 8875026432.0000\n",
      "Epoch 661/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8071297024.0000 - val_loss: 8728591360.0000\n",
      "Epoch 662/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7929143296.0000 - val_loss: 8507744256.0000\n",
      "Epoch 663/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7787649536.0000 - val_loss: 9317054464.0000\n",
      "Epoch 664/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7955765248.0000 - val_loss: 8696419328.0000\n",
      "Epoch 665/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7787215360.0000 - val_loss: 8722760704.0000\n",
      "Epoch 666/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8075117056.0000 - val_loss: 8488516096.0000\n",
      "Epoch 667/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7880799232.0000 - val_loss: 9399005184.0000\n",
      "Epoch 668/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7846682624.0000 - val_loss: 8526415360.0000\n",
      "Epoch 669/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7952996352.0000 - val_loss: 9226077184.0000\n",
      "Epoch 670/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7934258688.0000 - val_loss: 8870022144.0000\n",
      "Epoch 671/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7843594752.0000 - val_loss: 8534808064.0000\n",
      "Epoch 672/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7932681216.0000 - val_loss: 8551044096.0000\n",
      "Epoch 673/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7982362624.0000 - val_loss: 8534274560.0000\n",
      "Epoch 674/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7860775424.0000 - val_loss: 8515822592.0000\n",
      "Epoch 675/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7973790720.0000 - val_loss: 8452611072.0000\n",
      "Epoch 676/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7898306048.0000 - val_loss: 8635008000.0000\n",
      "Epoch 677/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7868565504.0000 - val_loss: 8538894848.0000\n",
      "Epoch 678/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7834161664.0000 - val_loss: 8988411904.0000\n",
      "Epoch 679/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7907414016.0000 - val_loss: 9392963584.0000\n",
      "Epoch 680/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7754464256.0000 - val_loss: 8769009664.0000\n",
      "Epoch 681/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7886925312.0000 - val_loss: 8784942080.0000\n",
      "Epoch 682/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7833866752.0000 - val_loss: 8470974976.0000\n",
      "Epoch 683/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7869956608.0000 - val_loss: 8569641984.0000\n",
      "Epoch 684/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8081369088.0000 - val_loss: 8636741632.0000\n",
      "Epoch 685/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7915914240.0000 - val_loss: 9030235136.0000\n",
      "Epoch 686/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7951617536.0000 - val_loss: 8492936704.0000\n",
      "Epoch 687/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7834785792.0000 - val_loss: 8551399936.0000\n",
      "Epoch 688/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8047889408.0000 - val_loss: 8603726848.0000\n",
      "Epoch 689/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7911696384.0000 - val_loss: 8969710592.0000\n",
      "Epoch 690/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7983539712.0000 - val_loss: 8826785792.0000\n",
      "Epoch 691/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7776116224.0000 - val_loss: 8461079040.0000\n",
      "Epoch 692/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7802528768.0000 - val_loss: 8500248064.0000\n",
      "Epoch 693/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7759917056.0000 - val_loss: 8464924160.0000\n",
      "Epoch 694/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7802182144.0000 - val_loss: 8672435200.0000\n",
      "Epoch 695/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7855628288.0000 - val_loss: 8486652416.0000\n",
      "Epoch 696/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7918633472.0000 - val_loss: 8972268544.0000\n",
      "Epoch 697/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7933346304.0000 - val_loss: 8505666048.0000\n",
      "Epoch 698/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7877194240.0000 - val_loss: 8846828544.0000\n",
      "Epoch 699/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7817935360.0000 - val_loss: 8433286144.0000\n",
      "Epoch 700/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7847740416.0000 - val_loss: 8667163648.0000\n",
      "Epoch 701/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7885559296.0000 - val_loss: 8870289408.0000\n",
      "Epoch 702/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7849068544.0000 - val_loss: 9043006464.0000\n",
      "Epoch 703/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7827608064.0000 - val_loss: 8629644288.0000\n",
      "Epoch 704/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7835465728.0000 - val_loss: 9157718016.0000\n",
      "Epoch 705/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7839085568.0000 - val_loss: 8559867904.0000\n",
      "Epoch 706/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7822873088.0000 - val_loss: 8444257792.0000\n",
      "Epoch 707/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7930493952.0000 - val_loss: 9217021952.0000\n",
      "Epoch 708/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7896417792.0000 - val_loss: 9219695616.0000\n",
      "Epoch 709/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7968963072.0000 - val_loss: 8531599872.0000\n",
      "Epoch 710/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7744016384.0000 - val_loss: 8486151680.0000\n",
      "Epoch 711/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7817184256.0000 - val_loss: 8975922176.0000\n",
      "Epoch 712/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7778588672.0000 - val_loss: 8583115264.0000\n",
      "Epoch 713/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7921963520.0000 - val_loss: 8978211840.0000\n",
      "Epoch 714/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8073538048.0000 - val_loss: 8542736384.0000\n",
      "Epoch 715/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7841320448.0000 - val_loss: 9065003008.0000\n",
      "Epoch 716/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7908125184.0000 - val_loss: 8550076928.0000\n",
      "Epoch 717/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7718363648.0000 - val_loss: 8565605888.0000\n",
      "Epoch 718/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7974047232.0000 - val_loss: 8601655296.0000\n",
      "Epoch 719/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8055370240.0000 - val_loss: 8627519488.0000\n",
      "Epoch 720/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7798847488.0000 - val_loss: 8441232384.0000\n",
      "Epoch 721/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7756393472.0000 - val_loss: 8513409024.0000\n",
      "Epoch 722/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7963124224.0000 - val_loss: 8577961984.0000\n",
      "Epoch 723/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7747531264.0000 - val_loss: 9283676160.0000\n",
      "Epoch 724/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7811047936.0000 - val_loss: 8480950784.0000\n",
      "Epoch 725/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7869905920.0000 - val_loss: 9843596288.0000\n",
      "Epoch 726/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8499565056.0000 - val_loss: 9732822016.0000\n",
      "Epoch 727/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8016073216.0000 - val_loss: 8954034176.0000\n",
      "Epoch 728/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7936768512.0000 - val_loss: 9129110528.0000\n",
      "Epoch 729/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7892818432.0000 - val_loss: 8470077440.0000\n",
      "Epoch 730/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7814378496.0000 - val_loss: 8689185792.0000\n",
      "Epoch 731/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7730926592.0000 - val_loss: 8452576768.0000\n",
      "Epoch 732/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7800760320.0000 - val_loss: 8463608832.0000\n",
      "Epoch 733/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7926322688.0000 - val_loss: 9047803904.0000\n",
      "Epoch 734/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7685058560.0000 - val_loss: 8692117504.0000\n",
      "Epoch 735/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7795396608.0000 - val_loss: 8577820672.0000\n",
      "Epoch 736/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7741816320.0000 - val_loss: 9004013568.0000\n",
      "Epoch 737/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8164461568.0000 - val_loss: 9065821184.0000\n",
      "Epoch 738/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7773941760.0000 - val_loss: 8456398848.0000\n",
      "Epoch 739/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7831565824.0000 - val_loss: 8605966336.0000\n",
      "Epoch 740/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7884663296.0000 - val_loss: 9109127168.0000\n",
      "Epoch 741/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7905510912.0000 - val_loss: 8724910080.0000\n",
      "Epoch 742/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7916253696.0000 - val_loss: 8579474944.0000\n",
      "Epoch 743/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7812892160.0000 - val_loss: 8481398784.0000\n",
      "Epoch 744/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7733696000.0000 - val_loss: 8481951232.0000\n",
      "Epoch 745/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7708057600.0000 - val_loss: 8406292480.0000\n",
      "Epoch 746/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8135120384.0000 - val_loss: 8422796800.0000\n",
      "Epoch 747/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7974945792.0000 - val_loss: 9537343488.0000\n",
      "Epoch 748/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7906267136.0000 - val_loss: 8666864640.0000\n",
      "Epoch 749/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7878864384.0000 - val_loss: 8458214912.0000\n",
      "Epoch 750/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7738897408.0000 - val_loss: 8400387584.0000\n",
      "Epoch 751/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7719762432.0000 - val_loss: 8515216896.0000\n",
      "Epoch 752/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7720222208.0000 - val_loss: 8399572480.0000\n",
      "Epoch 753/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7694969856.0000 - val_loss: 8480355840.0000\n",
      "Epoch 754/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7669679616.0000 - val_loss: 8419703808.0000\n",
      "Epoch 755/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7851964928.0000 - val_loss: 8432556032.0000\n",
      "Epoch 756/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7789795840.0000 - val_loss: 8877214720.0000\n",
      "Epoch 757/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7848821760.0000 - val_loss: 8491013120.0000\n",
      "Epoch 758/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7767581696.0000 - val_loss: 8501488128.0000\n",
      "Epoch 759/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7766185984.0000 - val_loss: 8478521344.0000\n",
      "Epoch 760/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7821675520.0000 - val_loss: 8621831168.0000\n",
      "Epoch 761/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7832138752.0000 - val_loss: 8461535744.0000\n",
      "Epoch 762/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7733756928.0000 - val_loss: 8684497920.0000\n",
      "Epoch 763/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7840693248.0000 - val_loss: 8427812864.0000\n",
      "Epoch 764/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7858513920.0000 - val_loss: 8743826432.0000\n",
      "Epoch 765/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8044869120.0000 - val_loss: 8723015680.0000\n",
      "Epoch 766/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7736607744.0000 - val_loss: 8397352960.0000\n",
      "Epoch 767/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7673497088.0000 - val_loss: 8571604992.0000\n",
      "Epoch 768/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7938338816.0000 - val_loss: 8900433920.0000\n",
      "Epoch 769/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7845625856.0000 - val_loss: 9477861376.0000\n",
      "Epoch 770/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7876528640.0000 - val_loss: 8440214528.0000\n",
      "Epoch 771/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7739557376.0000 - val_loss: 8905636864.0000\n",
      "Epoch 772/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7816176128.0000 - val_loss: 8802372608.0000\n",
      "Epoch 773/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7757873152.0000 - val_loss: 8614050816.0000\n",
      "Epoch 774/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7748769792.0000 - val_loss: 8450279936.0000\n",
      "Epoch 775/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7692938240.0000 - val_loss: 9386913792.0000\n",
      "Epoch 776/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7848874496.0000 - val_loss: 9090426880.0000\n",
      "Epoch 777/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7838009344.0000 - val_loss: 8411685888.0000\n",
      "Epoch 778/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7728543744.0000 - val_loss: 8595508224.0000\n",
      "Epoch 779/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7887531008.0000 - val_loss: 9481211904.0000\n",
      "Epoch 780/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7743031296.0000 - val_loss: 8973427712.0000\n",
      "Epoch 781/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7726432256.0000 - val_loss: 8451580416.0000\n",
      "Epoch 782/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7750894592.0000 - val_loss: 8751050752.0000\n",
      "Epoch 783/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7868614656.0000 - val_loss: 8484751360.0000\n",
      "Epoch 784/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7768865280.0000 - val_loss: 8833006592.0000\n",
      "Epoch 785/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7915610624.0000 - val_loss: 8866945024.0000\n",
      "Epoch 786/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7845014016.0000 - val_loss: 8389122048.0000\n",
      "Epoch 787/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7730465792.0000 - val_loss: 9092199424.0000\n",
      "Epoch 788/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7697505792.0000 - val_loss: 8618933248.0000\n",
      "Epoch 789/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7727186432.0000 - val_loss: 9108592640.0000\n",
      "Epoch 790/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7726759424.0000 - val_loss: 8535190528.0000\n",
      "Epoch 791/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 8053996544.0000 - val_loss: 8486780928.0000\n",
      "Epoch 792/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7649800704.0000 - val_loss: 8484972544.0000\n",
      "Epoch 793/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7651979776.0000 - val_loss: 8547642368.0000\n",
      "Epoch 794/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7764177408.0000 - val_loss: 8591097856.0000\n",
      "Epoch 795/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8061795328.0000 - val_loss: 9003752448.0000\n",
      "Epoch 796/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7731190784.0000 - val_loss: 8368197120.0000\n",
      "Epoch 797/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7795545600.0000 - val_loss: 8735352832.0000\n",
      "Epoch 798/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7847308288.0000 - val_loss: 8530684928.0000\n",
      "Epoch 799/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7842797568.0000 - val_loss: 9618872320.0000\n",
      "Epoch 800/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7661916160.0000 - val_loss: 8469273600.0000\n",
      "Epoch 801/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7995713024.0000 - val_loss: 8372311040.0000\n",
      "Epoch 802/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7705549312.0000 - val_loss: 8418903040.0000\n",
      "Epoch 803/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7796028416.0000 - val_loss: 8661500928.0000\n",
      "Epoch 804/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7874513408.0000 - val_loss: 8400777728.0000\n",
      "Epoch 805/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7738629632.0000 - val_loss: 8369818112.0000\n",
      "Epoch 806/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7715250688.0000 - val_loss: 8464617472.0000\n",
      "Epoch 807/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7858720768.0000 - val_loss: 8475156992.0000\n",
      "Epoch 808/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7924168192.0000 - val_loss: 8579110912.0000\n",
      "Epoch 809/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7801761792.0000 - val_loss: 8742307840.0000\n",
      "Epoch 810/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7811505152.0000 - val_loss: 9307842560.0000\n",
      "Epoch 811/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8072368640.0000 - val_loss: 8433518080.0000\n",
      "Epoch 812/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7796189696.0000 - val_loss: 8749232128.0000\n",
      "Epoch 813/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7767549440.0000 - val_loss: 8364806656.0000\n",
      "Epoch 814/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7647369728.0000 - val_loss: 8503590400.0000\n",
      "Epoch 815/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7958198784.0000 - val_loss: 8965410816.0000\n",
      "Epoch 816/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7717929984.0000 - val_loss: 8677435392.0000\n",
      "Epoch 817/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7729382912.0000 - val_loss: 8467877376.0000\n",
      "Epoch 818/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7824295936.0000 - val_loss: 8357315584.0000\n",
      "Epoch 819/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7719772672.0000 - val_loss: 8516981760.0000\n",
      "Epoch 820/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7859311616.0000 - val_loss: 8548222464.0000\n",
      "Epoch 821/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7640574464.0000 - val_loss: 8419572736.0000\n",
      "Epoch 822/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7993003520.0000 - val_loss: 8498562048.0000\n",
      "Epoch 823/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7708354560.0000 - val_loss: 8838686720.0000\n",
      "Epoch 824/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7757011968.0000 - val_loss: 8517026816.0000\n",
      "Epoch 825/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7805188096.0000 - val_loss: 8644839424.0000\n",
      "Epoch 826/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7804192256.0000 - val_loss: 8442866688.0000\n",
      "Epoch 827/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7801694208.0000 - val_loss: 8492520960.0000\n",
      "Epoch 828/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7971905024.0000 - val_loss: 8448988672.0000\n",
      "Epoch 829/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7824770560.0000 - val_loss: 8714373120.0000\n",
      "Epoch 830/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7921498624.0000 - val_loss: 8593570816.0000\n",
      "Epoch 831/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7760933376.0000 - val_loss: 8368599552.0000\n",
      "Epoch 832/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7795351040.0000 - val_loss: 8582528512.0000\n",
      "Epoch 833/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7829283328.0000 - val_loss: 9802583040.0000\n",
      "Epoch 834/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7788545536.0000 - val_loss: 8493423616.0000\n",
      "Epoch 835/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7801883136.0000 - val_loss: 8466584576.0000\n",
      "Epoch 836/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7787036672.0000 - val_loss: 9551360000.0000\n",
      "Epoch 837/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7768081408.0000 - val_loss: 8855542784.0000\n",
      "Epoch 838/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7888196608.0000 - val_loss: 8595266560.0000\n",
      "Epoch 839/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7750754304.0000 - val_loss: 8612835328.0000\n",
      "Epoch 840/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7731856384.0000 - val_loss: 8601759744.0000\n",
      "Epoch 841/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7810155520.0000 - val_loss: 8352665088.0000\n",
      "Epoch 842/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7825673728.0000 - val_loss: 8426728960.0000\n",
      "Epoch 843/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7755657216.0000 - val_loss: 8479949312.0000\n",
      "Epoch 844/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7680161280.0000 - val_loss: 8673015808.0000\n",
      "Epoch 845/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7768297984.0000 - val_loss: 8494154752.0000\n",
      "Epoch 846/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7652882432.0000 - val_loss: 8788134912.0000\n",
      "Epoch 847/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7743585792.0000 - val_loss: 8563522560.0000\n",
      "Epoch 848/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7809360384.0000 - val_loss: 8576628224.0000\n",
      "Epoch 849/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7986037760.0000 - val_loss: 9276132352.0000\n",
      "Epoch 850/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7677845504.0000 - val_loss: 8897852416.0000\n",
      "Epoch 851/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7802483712.0000 - val_loss: 8388994048.0000\n",
      "Epoch 852/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7728541184.0000 - val_loss: 8722406400.0000\n",
      "Epoch 853/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7802364928.0000 - val_loss: 9012371456.0000\n",
      "Epoch 854/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7604867072.0000 - val_loss: 8501649920.0000\n",
      "Epoch 855/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7696014848.0000 - val_loss: 8655774720.0000\n",
      "Epoch 856/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7622613504.0000 - val_loss: 8966502400.0000\n",
      "Epoch 857/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7744238080.0000 - val_loss: 8947820544.0000\n",
      "Epoch 858/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8506350080.0000 - val_loss: 8409794560.0000\n",
      "Epoch 859/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7773506560.0000 - val_loss: 8358125056.0000\n",
      "Epoch 860/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7736777216.0000 - val_loss: 8998652928.0000\n",
      "Epoch 861/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7759964160.0000 - val_loss: 8590481408.0000\n",
      "Epoch 862/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7787519488.0000 - val_loss: 8419126272.0000\n",
      "Epoch 863/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7798341120.0000 - val_loss: 8402020352.0000\n",
      "Epoch 864/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7792308224.0000 - val_loss: 8638400512.0000\n",
      "Epoch 865/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7936981504.0000 - val_loss: 9102868480.0000\n",
      "Epoch 866/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7701424128.0000 - val_loss: 8841400320.0000\n",
      "Epoch 867/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7913165824.0000 - val_loss: 8346412544.0000\n",
      "Epoch 868/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7739238400.0000 - val_loss: 8495087104.0000\n",
      "Epoch 869/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7693247488.0000 - val_loss: 8360415744.0000\n",
      "Epoch 870/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7725633024.0000 - val_loss: 8396648448.0000\n",
      "Epoch 871/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7878908928.0000 - val_loss: 8443429888.0000\n",
      "Epoch 872/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7604696576.0000 - val_loss: 8412970496.0000\n",
      "Epoch 873/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7783716864.0000 - val_loss: 8342243328.0000\n",
      "Epoch 874/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8199293440.0000 - val_loss: 10104526848.0000\n",
      "Epoch 875/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8028114432.0000 - val_loss: 8386544640.0000\n",
      "Epoch 876/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7652841984.0000 - val_loss: 8451768320.0000\n",
      "Epoch 877/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7643100672.0000 - val_loss: 8731120640.0000\n",
      "Epoch 878/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7699487232.0000 - val_loss: 8515022336.0000\n",
      "Epoch 879/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7719320576.0000 - val_loss: 8352497664.0000\n",
      "Epoch 880/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7717144064.0000 - val_loss: 8359791616.0000\n",
      "Epoch 881/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7673236480.0000 - val_loss: 8487706624.0000\n",
      "Epoch 882/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7698863104.0000 - val_loss: 8378314240.0000\n",
      "Epoch 883/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7735044608.0000 - val_loss: 8821289984.0000\n",
      "Epoch 884/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7828951040.0000 - val_loss: 8394579456.0000\n",
      "Epoch 885/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7696398848.0000 - val_loss: 8322930688.0000\n",
      "Epoch 886/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7675868672.0000 - val_loss: 8674739200.0000\n",
      "Epoch 887/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7636952064.0000 - val_loss: 8501056000.0000\n",
      "Epoch 888/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7561226240.0000 - val_loss: 8420439552.0000\n",
      "Epoch 889/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7779683328.0000 - val_loss: 8458471936.0000\n",
      "Epoch 890/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7699051520.0000 - val_loss: 8410132480.0000\n",
      "Epoch 891/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7758705664.0000 - val_loss: 8327204352.0000\n",
      "Epoch 892/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7844219904.0000 - val_loss: 8427629568.0000\n",
      "Epoch 893/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7719362560.0000 - val_loss: 8372118528.0000\n",
      "Epoch 894/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7699140096.0000 - val_loss: 9279498240.0000\n",
      "Epoch 895/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7676844544.0000 - val_loss: 8351492608.0000\n",
      "Epoch 896/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7653044224.0000 - val_loss: 8323841536.0000\n",
      "Epoch 897/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7658500096.0000 - val_loss: 8546170880.0000\n",
      "Epoch 898/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7742075904.0000 - val_loss: 8344920576.0000\n",
      "Epoch 899/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7867427328.0000 - val_loss: 8736245760.0000\n",
      "Epoch 900/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7685710336.0000 - val_loss: 8346603008.0000\n",
      "Epoch 901/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7672666624.0000 - val_loss: 9203646464.0000\n",
      "Epoch 902/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7826291712.0000 - val_loss: 8426636800.0000\n",
      "Epoch 903/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7693525504.0000 - val_loss: 8785831936.0000\n",
      "Epoch 904/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7574785536.0000 - val_loss: 8368715264.0000\n",
      "Epoch 905/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7669559808.0000 - val_loss: 8340282368.0000\n",
      "Epoch 906/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7730831872.0000 - val_loss: 8349052928.0000\n",
      "Epoch 907/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7984920576.0000 - val_loss: 9160469504.0000\n",
      "Epoch 908/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7698375680.0000 - val_loss: 8350225920.0000\n",
      "Epoch 909/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7650430976.0000 - val_loss: 8322875904.0000\n",
      "Epoch 910/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7676148224.0000 - val_loss: 8434953728.0000\n",
      "Epoch 911/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7676728832.0000 - val_loss: 8290796544.0000\n",
      "Epoch 912/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7737446400.0000 - val_loss: 8558544384.0000\n",
      "Epoch 913/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7667370496.0000 - val_loss: 8637276160.0000\n",
      "Epoch 914/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7680438784.0000 - val_loss: 8597373952.0000\n",
      "Epoch 915/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7617271808.0000 - val_loss: 10808113152.0000\n",
      "Epoch 916/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7768183296.0000 - val_loss: 8452945920.0000\n",
      "Epoch 917/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7654179840.0000 - val_loss: 8384762880.0000\n",
      "Epoch 918/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7583410688.0000 - val_loss: 8316203008.0000\n",
      "Epoch 919/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7662575104.0000 - val_loss: 8352737280.0000\n",
      "Epoch 920/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7559629824.0000 - val_loss: 9595541504.0000\n",
      "Epoch 921/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7670851584.0000 - val_loss: 8306154496.0000\n",
      "Epoch 922/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7631353344.0000 - val_loss: 8409529856.0000\n",
      "Epoch 923/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7693123072.0000 - val_loss: 8712196096.0000\n",
      "Epoch 924/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7765941760.0000 - val_loss: 8334396928.0000\n",
      "Epoch 925/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7797792256.0000 - val_loss: 8416962048.0000\n",
      "Epoch 926/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7554911232.0000 - val_loss: 8516115968.0000\n",
      "Epoch 927/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7672636928.0000 - val_loss: 8325196800.0000\n",
      "Epoch 928/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7674440192.0000 - val_loss: 8338497024.0000\n",
      "Epoch 929/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7733549056.0000 - val_loss: 8443343872.0000\n",
      "Epoch 930/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7582946816.0000 - val_loss: 8378320896.0000\n",
      "Epoch 931/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7652898304.0000 - val_loss: 8284549120.0000\n",
      "Epoch 932/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7487694336.0000 - val_loss: 9248321536.0000\n",
      "Epoch 933/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7935191040.0000 - val_loss: 10520467456.0000\n",
      "Epoch 934/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7826416640.0000 - val_loss: 8303528960.0000\n",
      "Epoch 935/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7645751296.0000 - val_loss: 8503050752.0000\n",
      "Epoch 936/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7659033088.0000 - val_loss: 8529887744.0000\n",
      "Epoch 937/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7666456064.0000 - val_loss: 8397729792.0000\n",
      "Epoch 938/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7885286400.0000 - val_loss: 8693468160.0000\n",
      "Epoch 939/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7785320960.0000 - val_loss: 8706052096.0000\n",
      "Epoch 940/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500283904.0000 - val_loss: 8313500672.0000\n",
      "Epoch 941/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7859198976.0000 - val_loss: 8561581056.0000\n",
      "Epoch 942/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7687056896.0000 - val_loss: 9278699520.0000\n",
      "Epoch 943/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7681987584.0000 - val_loss: 8295510528.0000\n",
      "Epoch 944/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7573268992.0000 - val_loss: 8297670656.0000\n",
      "Epoch 945/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7528690688.0000 - val_loss: 8882786304.0000\n",
      "Epoch 946/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7704263680.0000 - val_loss: 8377998848.0000\n",
      "Epoch 947/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7681142272.0000 - val_loss: 9566419968.0000\n",
      "Epoch 948/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7673277952.0000 - val_loss: 8444403712.0000\n",
      "Epoch 949/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7680636928.0000 - val_loss: 8761664512.0000\n",
      "Epoch 950/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8007741952.0000 - val_loss: 8595309568.0000\n",
      "Epoch 951/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7782343680.0000 - val_loss: 8282671104.0000\n",
      "Epoch 952/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7648638976.0000 - val_loss: 10174990336.0000\n",
      "Epoch 953/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7777235968.0000 - val_loss: 8542658560.0000\n",
      "Epoch 954/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7698148864.0000 - val_loss: 8436117504.0000\n",
      "Epoch 955/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7629233664.0000 - val_loss: 8309506560.0000\n",
      "Epoch 956/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7623997440.0000 - val_loss: 8414831616.0000\n",
      "Epoch 957/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7569428992.0000 - val_loss: 8759940096.0000\n",
      "Epoch 958/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7700228096.0000 - val_loss: 8398260224.0000\n",
      "Epoch 959/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7714587648.0000 - val_loss: 8506866176.0000\n",
      "Epoch 960/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7764847616.0000 - val_loss: 8511846400.0000\n",
      "Epoch 961/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7612999168.0000 - val_loss: 8710128640.0000\n",
      "Epoch 962/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7522806272.0000 - val_loss: 8402420224.0000\n",
      "Epoch 963/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7755226112.0000 - val_loss: 8431282176.0000\n",
      "Epoch 964/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548430848.0000 - val_loss: 8347561984.0000\n",
      "Epoch 965/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7666759680.0000 - val_loss: 8971934720.0000\n",
      "Epoch 966/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7856311808.0000 - val_loss: 8271133696.0000\n",
      "Epoch 967/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7706882048.0000 - val_loss: 8356320768.0000\n",
      "Epoch 968/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7743893504.0000 - val_loss: 8365628416.0000\n",
      "Epoch 969/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7714912256.0000 - val_loss: 8645422080.0000\n",
      "Epoch 970/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7843769856.0000 - val_loss: 8338405888.0000\n",
      "Epoch 971/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7634848768.0000 - val_loss: 8324464128.0000\n",
      "Epoch 972/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7572280320.0000 - val_loss: 8396851200.0000\n",
      "Epoch 973/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7540081152.0000 - val_loss: 8343725056.0000\n",
      "Epoch 974/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7542701568.0000 - val_loss: 8500543488.0000\n",
      "Epoch 975/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7730769920.0000 - val_loss: 9194920960.0000\n",
      "Epoch 976/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7713827840.0000 - val_loss: 8386169344.0000\n",
      "Epoch 977/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7916023296.0000 - val_loss: 8747174912.0000\n",
      "Epoch 978/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7581863424.0000 - val_loss: 8334664704.0000\n",
      "Epoch 979/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7506098688.0000 - val_loss: 8366263808.0000\n",
      "Epoch 980/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7561187840.0000 - val_loss: 8334553600.0000\n",
      "Epoch 981/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7829316096.0000 - val_loss: 8455710720.0000\n",
      "Epoch 982/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7601043968.0000 - val_loss: 8299648000.0000\n",
      "Epoch 983/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7624018944.0000 - val_loss: 8323668480.0000\n",
      "Epoch 984/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7615371264.0000 - val_loss: 9851570176.0000\n",
      "Epoch 985/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7793730560.0000 - val_loss: 8564251136.0000\n",
      "Epoch 986/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7743158272.0000 - val_loss: 8347603456.0000\n",
      "Epoch 987/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7743817728.0000 - val_loss: 8486993920.0000\n",
      "Epoch 988/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7528887808.0000 - val_loss: 8394584576.0000\n",
      "Epoch 989/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7517233664.0000 - val_loss: 8842057728.0000\n",
      "Epoch 990/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560342528.0000 - val_loss: 8308440064.0000\n",
      "Epoch 991/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560816640.0000 - val_loss: 8976788480.0000\n",
      "Epoch 992/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7744675840.0000 - val_loss: 8385035776.0000\n",
      "Epoch 993/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7952550400.0000 - val_loss: 8283791872.0000\n",
      "Epoch 994/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7671095808.0000 - val_loss: 8876164096.0000\n",
      "Epoch 995/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7625565184.0000 - val_loss: 8449619968.0000\n",
      "Epoch 996/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7849920512.0000 - val_loss: 8419767296.0000\n",
      "Epoch 997/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7658423296.0000 - val_loss: 9030668288.0000\n",
      "Epoch 998/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7759596032.0000 - val_loss: 8596746240.0000\n",
      "Epoch 999/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7576514048.0000 - val_loss: 8549513728.0000\n",
      "Epoch 1000/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7567076864.0000 - val_loss: 8697419776.0000\n",
      "Epoch 1001/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7572839936.0000 - val_loss: 8292437504.0000\n",
      "Epoch 1002/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7652692480.0000 - val_loss: 8376324608.0000\n",
      "Epoch 1003/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7647851008.0000 - val_loss: 8315078144.0000\n",
      "Epoch 1004/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7667701248.0000 - val_loss: 8352052224.0000\n",
      "Epoch 1005/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7651392512.0000 - val_loss: 8268843520.0000\n",
      "Epoch 1006/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7556420608.0000 - val_loss: 8441938944.0000\n",
      "Epoch 1007/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7830770688.0000 - val_loss: 9698037760.0000\n",
      "Epoch 1008/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7762056704.0000 - val_loss: 8724732928.0000\n",
      "Epoch 1009/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7759614976.0000 - val_loss: 8615556096.0000\n",
      "Epoch 1010/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7564556800.0000 - val_loss: 8346283520.0000\n",
      "Epoch 1011/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7547023872.0000 - val_loss: 8351875584.0000\n",
      "Epoch 1012/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7568368640.0000 - val_loss: 8502466048.0000\n",
      "Epoch 1013/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7507798528.0000 - val_loss: 8678831104.0000\n",
      "Epoch 1014/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7620744704.0000 - val_loss: 8508335616.0000\n",
      "Epoch 1015/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7469580800.0000 - val_loss: 8367910912.0000\n",
      "Epoch 1016/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7632140800.0000 - val_loss: 8391747584.0000\n",
      "Epoch 1017/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7673679872.0000 - val_loss: 8601260032.0000\n",
      "Epoch 1018/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7910566912.0000 - val_loss: 8309543424.0000\n",
      "Epoch 1019/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7622228992.0000 - val_loss: 8468737536.0000\n",
      "Epoch 1020/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7762903552.0000 - val_loss: 8460447744.0000\n",
      "Epoch 1021/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7618669056.0000 - val_loss: 8508849664.0000\n",
      "Epoch 1022/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7725261824.0000 - val_loss: 8478962688.0000\n",
      "Epoch 1023/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7606901760.0000 - val_loss: 8814114816.0000\n",
      "Epoch 1024/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7590422016.0000 - val_loss: 8297867264.0000\n",
      "Epoch 1025/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7555424256.0000 - val_loss: 8288805376.0000\n",
      "Epoch 1026/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7656834560.0000 - val_loss: 8748987392.0000\n",
      "Epoch 1027/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7565914112.0000 - val_loss: 8605707264.0000\n",
      "Epoch 1028/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7599963648.0000 - val_loss: 8518606336.0000\n",
      "Epoch 1029/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7783440896.0000 - val_loss: 8421435904.0000\n",
      "Epoch 1030/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7586157056.0000 - val_loss: 8288591360.0000\n",
      "Epoch 1031/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7579756032.0000 - val_loss: 8757881856.0000\n",
      "Epoch 1032/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7703839232.0000 - val_loss: 8286799360.0000\n",
      "Epoch 1033/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7551093760.0000 - val_loss: 8513008128.0000\n",
      "Epoch 1034/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7590905856.0000 - val_loss: 8347952128.0000\n",
      "Epoch 1035/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7546354688.0000 - val_loss: 8549167616.0000\n",
      "Epoch 1036/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7999158784.0000 - val_loss: 8403217408.0000\n",
      "Epoch 1037/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7568169472.0000 - val_loss: 8783849472.0000\n",
      "Epoch 1038/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7646921216.0000 - val_loss: 8843268096.0000\n",
      "Epoch 1039/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7720949248.0000 - val_loss: 8416845312.0000\n",
      "Epoch 1040/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7678346752.0000 - val_loss: 8788357120.0000\n",
      "Epoch 1041/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7739855360.0000 - val_loss: 8472200704.0000\n",
      "Epoch 1042/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7634030080.0000 - val_loss: 8375377920.0000\n",
      "Epoch 1043/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7852045824.0000 - val_loss: 8314629120.0000\n",
      "Epoch 1044/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7714969088.0000 - val_loss: 9125357568.0000\n",
      "Epoch 1045/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7659292160.0000 - val_loss: 8747006976.0000\n",
      "Epoch 1046/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7652297728.0000 - val_loss: 8253668864.0000\n",
      "Epoch 1047/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7535988736.0000 - val_loss: 8554152960.0000\n",
      "Epoch 1048/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7619185152.0000 - val_loss: 9136220160.0000\n",
      "Epoch 1049/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7537072640.0000 - val_loss: 8689721344.0000\n",
      "Epoch 1050/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7606635520.0000 - val_loss: 8759425024.0000\n",
      "Epoch 1051/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7568154624.0000 - val_loss: 8416991744.0000\n",
      "Epoch 1052/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7594549760.0000 - val_loss: 8252063744.0000\n",
      "Epoch 1053/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7616669696.0000 - val_loss: 8303780352.0000\n",
      "Epoch 1054/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7522231296.0000 - val_loss: 8912706560.0000\n",
      "Epoch 1055/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7857647616.0000 - val_loss: 9379362816.0000\n",
      "Epoch 1056/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7612067840.0000 - val_loss: 8314397696.0000\n",
      "Epoch 1057/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7588835328.0000 - val_loss: 8739045376.0000\n",
      "Epoch 1058/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7540288000.0000 - val_loss: 8282855936.0000\n",
      "Epoch 1059/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7673213952.0000 - val_loss: 8420310528.0000\n",
      "Epoch 1060/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7912500736.0000 - val_loss: 8263537664.0000\n",
      "Epoch 1061/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7462059520.0000 - val_loss: 8836943872.0000\n",
      "Epoch 1062/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7675712000.0000 - val_loss: 8398217216.0000\n",
      "Epoch 1063/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7790008832.0000 - val_loss: 9763235840.0000\n",
      "Epoch 1064/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7789649920.0000 - val_loss: 8858952704.0000\n",
      "Epoch 1065/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7669937664.0000 - val_loss: 8278378496.0000\n",
      "Epoch 1066/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7600344064.0000 - val_loss: 8258724352.0000\n",
      "Epoch 1067/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7578362368.0000 - val_loss: 8783925248.0000\n",
      "Epoch 1068/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7660219392.0000 - val_loss: 9933581312.0000\n",
      "Epoch 1069/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7688754176.0000 - val_loss: 8262007808.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1070/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7722660352.0000 - val_loss: 8296507392.0000\n",
      "Epoch 1071/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7580864512.0000 - val_loss: 8327880704.0000\n",
      "Epoch 1072/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7590945280.0000 - val_loss: 8804442112.0000\n",
      "Epoch 1073/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7535388672.0000 - val_loss: 8439594496.0000\n",
      "Epoch 1074/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548421632.0000 - val_loss: 8283170816.0000\n",
      "Epoch 1075/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7575570944.0000 - val_loss: 8282838016.0000\n",
      "Epoch 1076/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7541752320.0000 - val_loss: 8323482112.0000\n",
      "Epoch 1077/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7559168512.0000 - val_loss: 9250296832.0000\n",
      "Epoch 1078/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7551971328.0000 - val_loss: 8384763392.0000\n",
      "Epoch 1079/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7615941120.0000 - val_loss: 9275764736.0000\n",
      "Epoch 1080/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500681216.0000 - val_loss: 8381455872.0000\n",
      "Epoch 1081/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7693405696.0000 - val_loss: 8348828672.0000\n",
      "Epoch 1082/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560095744.0000 - val_loss: 8329222144.0000\n",
      "Epoch 1083/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7489330688.0000 - val_loss: 8389132288.0000\n",
      "Epoch 1084/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7613329920.0000 - val_loss: 8300750336.0000\n",
      "Epoch 1085/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7862403072.0000 - val_loss: 9429222400.0000\n",
      "Epoch 1086/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7493211136.0000 - val_loss: 8440294912.0000\n",
      "Epoch 1087/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7582469632.0000 - val_loss: 8244514304.0000\n",
      "Epoch 1088/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7593113600.0000 - val_loss: 8673765376.0000\n",
      "Epoch 1089/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7513808384.0000 - val_loss: 8606725120.0000\n",
      "Epoch 1090/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7685623296.0000 - val_loss: 8627511296.0000\n",
      "Epoch 1091/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7592334848.0000 - val_loss: 9315094528.0000\n",
      "Epoch 1092/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7835098112.0000 - val_loss: 8594732032.0000\n",
      "Epoch 1093/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7644699648.0000 - val_loss: 8822279168.0000\n",
      "Epoch 1094/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7617102848.0000 - val_loss: 8331755008.0000\n",
      "Epoch 1095/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7769351168.0000 - val_loss: 8244697600.0000\n",
      "Epoch 1096/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7499494400.0000 - val_loss: 8303566336.0000\n",
      "Epoch 1097/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7633076736.0000 - val_loss: 8317603328.0000\n",
      "Epoch 1098/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7488975360.0000 - val_loss: 8933450752.0000\n",
      "Epoch 1099/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7599999488.0000 - val_loss: 8265030656.0000\n",
      "Epoch 1100/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7590399488.0000 - val_loss: 8257103360.0000\n",
      "Epoch 1101/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7632241664.0000 - val_loss: 8951053312.0000\n",
      "Epoch 1102/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7735182336.0000 - val_loss: 8305644544.0000\n",
      "Epoch 1103/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7638396928.0000 - val_loss: 8235155456.0000\n",
      "Epoch 1104/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7775748096.0000 - val_loss: 9141146624.0000\n",
      "Epoch 1105/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7749102592.0000 - val_loss: 8279233536.0000\n",
      "Epoch 1106/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7616277504.0000 - val_loss: 8293596672.0000\n",
      "Epoch 1107/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7682527232.0000 - val_loss: 8377129984.0000\n",
      "Epoch 1108/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7597403648.0000 - val_loss: 8583524864.0000\n",
      "Epoch 1109/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7463579648.0000 - val_loss: 8497686016.0000\n",
      "Epoch 1110/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7493840384.0000 - val_loss: 10081727488.0000\n",
      "Epoch 1111/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7558891520.0000 - val_loss: 8413366784.0000\n",
      "Epoch 1112/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7522579456.0000 - val_loss: 8282598912.0000\n",
      "Epoch 1113/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7579723264.0000 - val_loss: 8750504960.0000\n",
      "Epoch 1114/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7779575296.0000 - val_loss: 8222661632.0000\n",
      "Epoch 1115/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560196096.0000 - val_loss: 8287799808.0000\n",
      "Epoch 1116/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7442788352.0000 - val_loss: 8284567040.0000\n",
      "Epoch 1117/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7484173312.0000 - val_loss: 8286709248.0000\n",
      "Epoch 1118/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7531694080.0000 - val_loss: 8223592960.0000\n",
      "Epoch 1119/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7852948480.0000 - val_loss: 8840774656.0000\n",
      "Epoch 1120/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560514560.0000 - val_loss: 8242743296.0000\n",
      "Epoch 1121/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7712906240.0000 - val_loss: 8970161152.0000\n",
      "Epoch 1122/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7583251456.0000 - val_loss: 8489053696.0000\n",
      "Epoch 1123/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7786681856.0000 - val_loss: 8485908480.0000\n",
      "Epoch 1124/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7615417344.0000 - val_loss: 8734288896.0000\n",
      "Epoch 1125/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7540166656.0000 - val_loss: 8324080640.0000\n",
      "Epoch 1126/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7541137920.0000 - val_loss: 8337917440.0000\n",
      "Epoch 1127/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7808584192.0000 - val_loss: 8310636544.0000\n",
      "Epoch 1128/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7706050560.0000 - val_loss: 8373109248.0000\n",
      "Epoch 1129/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7481813504.0000 - val_loss: 8437342720.0000\n",
      "Epoch 1130/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7477898240.0000 - val_loss: 8601128960.0000\n",
      "Epoch 1131/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7483671040.0000 - val_loss: 8246170112.0000\n",
      "Epoch 1132/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7507127296.0000 - val_loss: 8680291328.0000\n",
      "Epoch 1133/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7536225792.0000 - val_loss: 8226884608.0000\n",
      "Epoch 1134/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7611389952.0000 - val_loss: 9103114240.0000\n",
      "Epoch 1135/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7713812992.0000 - val_loss: 8352091136.0000\n",
      "Epoch 1136/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7555953152.0000 - val_loss: 8264942592.0000\n",
      "Epoch 1137/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7488147456.0000 - val_loss: 9569632256.0000\n",
      "Epoch 1138/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7629190144.0000 - val_loss: 8959742976.0000\n",
      "Epoch 1139/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7679750656.0000 - val_loss: 8204528640.0000\n",
      "Epoch 1140/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7530987520.0000 - val_loss: 8419278336.0000\n",
      "Epoch 1141/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7668089856.0000 - val_loss: 8474416640.0000\n",
      "Epoch 1142/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7452992000.0000 - val_loss: 8243999232.0000\n",
      "Epoch 1143/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548889600.0000 - val_loss: 8518890496.0000\n",
      "Epoch 1144/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7585347072.0000 - val_loss: 8375941120.0000\n",
      "Epoch 1145/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7541340160.0000 - val_loss: 8711882752.0000\n",
      "Epoch 1146/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7788783616.0000 - val_loss: 8470691328.0000\n",
      "Epoch 1147/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7584394240.0000 - val_loss: 8203832320.0000\n",
      "Epoch 1148/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7444790784.0000 - val_loss: 8550995968.0000\n",
      "Epoch 1149/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7490738688.0000 - val_loss: 8248546304.0000\n",
      "Epoch 1150/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7809240064.0000 - val_loss: 9143058432.0000\n",
      "Epoch 1151/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7481270272.0000 - val_loss: 8414287360.0000\n",
      "Epoch 1152/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7678628352.0000 - val_loss: 8804214784.0000\n",
      "Epoch 1153/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7524395008.0000 - val_loss: 8258279936.0000\n",
      "Epoch 1154/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7450092544.0000 - val_loss: 8907091968.0000\n",
      "Epoch 1155/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7912336896.0000 - val_loss: 8216276992.0000\n",
      "Epoch 1156/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7496321536.0000 - val_loss: 9199815680.0000\n",
      "Epoch 1157/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7575994368.0000 - val_loss: 8375921664.0000\n",
      "Epoch 1158/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7457168896.0000 - val_loss: 8320973312.0000\n",
      "Epoch 1159/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7489808384.0000 - val_loss: 8230673408.0000\n",
      "Epoch 1160/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7521045504.0000 - val_loss: 8280837632.0000\n",
      "Epoch 1161/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7475922432.0000 - val_loss: 8323011584.0000\n",
      "Epoch 1162/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7526672384.0000 - val_loss: 8243124736.0000\n",
      "Epoch 1163/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7503862784.0000 - val_loss: 8184321024.0000\n",
      "Epoch 1164/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7588820480.0000 - val_loss: 8329108480.0000\n",
      "Epoch 1165/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7452487168.0000 - val_loss: 8260768768.0000\n",
      "Epoch 1166/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7456464384.0000 - val_loss: 8345306112.0000\n",
      "Epoch 1167/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7506842112.0000 - val_loss: 8221180928.0000\n",
      "Epoch 1168/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7447212032.0000 - val_loss: 9001569280.0000\n",
      "Epoch 1169/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7822009344.0000 - val_loss: 8278339584.0000\n",
      "Epoch 1170/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7599041024.0000 - val_loss: 8884568064.0000\n",
      "Epoch 1171/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7515279360.0000 - val_loss: 8733572096.0000\n",
      "Epoch 1172/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548848128.0000 - val_loss: 8837194752.0000\n",
      "Epoch 1173/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7729137152.0000 - val_loss: 8319390208.0000\n",
      "Epoch 1174/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7726362112.0000 - val_loss: 8243089920.0000\n",
      "Epoch 1175/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7546661376.0000 - val_loss: 8250024448.0000\n",
      "Epoch 1176/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7472696320.0000 - val_loss: 8283537408.0000\n",
      "Epoch 1177/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7720356864.0000 - val_loss: 8445445632.0000\n",
      "Epoch 1178/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7587262464.0000 - val_loss: 10040318976.0000\n",
      "Epoch 1179/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7691299840.0000 - val_loss: 8225961984.0000\n",
      "Epoch 1180/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7416336384.0000 - val_loss: 8444404224.0000\n",
      "Epoch 1181/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7376544256.0000 - val_loss: 8234107904.0000\n",
      "Epoch 1182/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7538474496.0000 - val_loss: 8291451392.0000\n",
      "Epoch 1183/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7594037760.0000 - val_loss: 8252218880.0000\n",
      "Epoch 1184/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7516630016.0000 - val_loss: 8391516160.0000\n",
      "Epoch 1185/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7464114176.0000 - val_loss: 8201683456.0000\n",
      "Epoch 1186/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7765651456.0000 - val_loss: 8286639104.0000\n",
      "Epoch 1187/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7468076544.0000 - val_loss: 8585078272.0000\n",
      "Epoch 1188/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7393746432.0000 - val_loss: 8324715520.0000\n",
      "Epoch 1189/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7453891584.0000 - val_loss: 8604341248.0000\n",
      "Epoch 1190/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7624670208.0000 - val_loss: 8347320832.0000\n",
      "Epoch 1191/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7476546048.0000 - val_loss: 8652393472.0000\n",
      "Epoch 1192/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7730606080.0000 - val_loss: 8726692864.0000\n",
      "Epoch 1193/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7779627008.0000 - val_loss: 10408286208.0000\n",
      "Epoch 1194/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7525609984.0000 - val_loss: 8548575232.0000\n",
      "Epoch 1195/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7613900288.0000 - val_loss: 9142309888.0000\n",
      "Epoch 1196/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7476377088.0000 - val_loss: 8522169344.0000\n",
      "Epoch 1197/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7658506752.0000 - val_loss: 8596110336.0000\n",
      "Epoch 1198/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7502220800.0000 - val_loss: 8964224000.0000\n",
      "Epoch 1199/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7748801536.0000 - val_loss: 8386721280.0000\n",
      "Epoch 1200/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7513775616.0000 - val_loss: 8237721088.0000\n",
      "Epoch 1201/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7572923904.0000 - val_loss: 8258266112.0000\n",
      "Epoch 1202/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7514732544.0000 - val_loss: 8212184576.0000\n",
      "Epoch 1203/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7760956928.0000 - val_loss: 8210313216.0000\n",
      "Epoch 1204/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7578799104.0000 - val_loss: 8294411264.0000\n",
      "Epoch 1205/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7657441280.0000 - val_loss: 8430905856.0000\n",
      "Epoch 1206/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7837006336.0000 - val_loss: 8888413184.0000\n",
      "Epoch 1207/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7458963968.0000 - val_loss: 8365585920.0000\n",
      "Epoch 1208/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7765531648.0000 - val_loss: 8399848448.0000\n",
      "Epoch 1209/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7610492416.0000 - val_loss: 8542027776.0000\n",
      "Epoch 1210/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7581759488.0000 - val_loss: 8831669248.0000\n",
      "Epoch 1211/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7584890368.0000 - val_loss: 8377385984.0000\n",
      "Epoch 1212/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7462780416.0000 - val_loss: 8905160704.0000\n",
      "Epoch 1213/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7443273216.0000 - val_loss: 8382821888.0000\n",
      "Epoch 1214/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7597105664.0000 - val_loss: 8264513536.0000\n",
      "Epoch 1215/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7389039104.0000 - val_loss: 8174763520.0000\n",
      "Epoch 1216/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7565987840.0000 - val_loss: 8376080384.0000\n",
      "Epoch 1217/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7602960384.0000 - val_loss: 8320305152.0000\n",
      "Epoch 1218/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7489273344.0000 - val_loss: 8439929344.0000\n",
      "Epoch 1219/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7493721088.0000 - val_loss: 8348508160.0000\n",
      "Epoch 1220/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7573932032.0000 - val_loss: 8866787328.0000\n",
      "Epoch 1221/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7604196352.0000 - val_loss: 8489403392.0000\n",
      "Epoch 1222/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7627274752.0000 - val_loss: 8302702592.0000\n",
      "Epoch 1223/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7452681728.0000 - val_loss: 8393561600.0000\n",
      "Epoch 1224/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7406246400.0000 - val_loss: 8196353024.0000\n",
      "Epoch 1225/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7474897408.0000 - val_loss: 8202488832.0000\n",
      "Epoch 1226/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7487782912.0000 - val_loss: 8221031424.0000\n",
      "Epoch 1227/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7552495104.0000 - val_loss: 8259512320.0000\n",
      "Epoch 1228/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7476284416.0000 - val_loss: 10082695168.0000\n",
      "Epoch 1229/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7621694976.0000 - val_loss: 8393446912.0000\n",
      "Epoch 1230/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7559344128.0000 - val_loss: 8916079616.0000\n",
      "Epoch 1231/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7575732224.0000 - val_loss: 8373426688.0000\n",
      "Epoch 1232/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7470903296.0000 - val_loss: 8702800896.0000\n",
      "Epoch 1233/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7559925248.0000 - val_loss: 8294089728.0000\n",
      "Epoch 1234/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560586240.0000 - val_loss: 8475224064.0000\n",
      "Epoch 1235/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7700119552.0000 - val_loss: 8245472256.0000\n",
      "Epoch 1236/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7744649216.0000 - val_loss: 8869950464.0000\n",
      "Epoch 1237/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7523996160.0000 - val_loss: 8252378624.0000\n",
      "Epoch 1238/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7459653120.0000 - val_loss: 8437414912.0000\n",
      "Epoch 1239/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7484039168.0000 - val_loss: 8207671296.0000\n",
      "Epoch 1240/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7560097792.0000 - val_loss: 8492299264.0000\n",
      "Epoch 1241/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7664950272.0000 - val_loss: 8180887552.0000\n",
      "Epoch 1242/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7422415872.0000 - val_loss: 8885811200.0000\n",
      "Epoch 1243/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7582073856.0000 - val_loss: 8552698880.0000\n",
      "Epoch 1244/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7580103680.0000 - val_loss: 8214862336.0000\n",
      "Epoch 1245/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7487602688.0000 - val_loss: 8218119168.0000\n",
      "Epoch 1246/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7496574976.0000 - val_loss: 8368632832.0000\n",
      "Epoch 1247/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7858103808.0000 - val_loss: 8284750848.0000\n",
      "Epoch 1248/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7415451648.0000 - val_loss: 8324632064.0000\n",
      "Epoch 1249/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7604141568.0000 - val_loss: 8498335232.0000\n",
      "Epoch 1250/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7405826560.0000 - val_loss: 8207884800.0000\n",
      "Epoch 1251/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7471083008.0000 - val_loss: 8326060544.0000\n",
      "Epoch 1252/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7635098624.0000 - val_loss: 8186943488.0000\n",
      "Epoch 1253/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7462508544.0000 - val_loss: 9815788544.0000\n",
      "Epoch 1254/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7730670592.0000 - val_loss: 8321795584.0000\n",
      "Epoch 1255/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7521795584.0000 - val_loss: 8915321856.0000\n",
      "Epoch 1256/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7511143936.0000 - val_loss: 8165337088.0000\n",
      "Epoch 1257/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7360404480.0000 - val_loss: 8250346496.0000\n",
      "Epoch 1258/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7663278592.0000 - val_loss: 8213906944.0000\n",
      "Epoch 1259/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7607138304.0000 - val_loss: 8290123264.0000\n",
      "Epoch 1260/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7864096768.0000 - val_loss: 8274591232.0000\n",
      "Epoch 1261/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7546679296.0000 - val_loss: 8532080640.0000\n",
      "Epoch 1262/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7763201024.0000 - val_loss: 8159685632.0000\n",
      "Epoch 1263/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7475635200.0000 - val_loss: 8269934592.0000\n",
      "Epoch 1264/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7685339648.0000 - val_loss: 8283777536.0000\n",
      "Epoch 1265/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7481745920.0000 - val_loss: 8411231232.0000\n",
      "Epoch 1266/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7553336832.0000 - val_loss: 8196030976.0000\n",
      "Epoch 1267/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7509697024.0000 - val_loss: 8720812032.0000\n",
      "Epoch 1268/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7581459968.0000 - val_loss: 8197210112.0000\n",
      "Epoch 1269/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7507920896.0000 - val_loss: 8459986432.0000\n",
      "Epoch 1270/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7660676608.0000 - val_loss: 8275028480.0000\n",
      "Epoch 1271/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7457644032.0000 - val_loss: 9635540992.0000\n",
      "Epoch 1272/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7755592704.0000 - val_loss: 8293012992.0000\n",
      "Epoch 1273/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7655628288.0000 - val_loss: 8387650048.0000\n",
      "Epoch 1274/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7476484608.0000 - val_loss: 8523458048.0000\n",
      "Epoch 1275/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7463884288.0000 - val_loss: 8431379968.0000\n",
      "Epoch 1276/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7503053312.0000 - val_loss: 8222084096.0000\n",
      "Epoch 1277/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7435639808.0000 - val_loss: 8317710848.0000\n",
      "Epoch 1278/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7628908544.0000 - val_loss: 8859000832.0000\n",
      "Epoch 1279/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7475939840.0000 - val_loss: 8190606336.0000\n",
      "Epoch 1280/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7527444480.0000 - val_loss: 8835519488.0000\n",
      "Epoch 1281/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7459205632.0000 - val_loss: 8195465216.0000\n",
      "Epoch 1282/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7607647744.0000 - val_loss: 8613407744.0000\n",
      "Epoch 1283/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7598610944.0000 - val_loss: 8230194688.0000\n",
      "Epoch 1284/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7496434176.0000 - val_loss: 8309649920.0000\n",
      "Epoch 1285/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7458367488.0000 - val_loss: 8699783168.0000\n",
      "Epoch 1286/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7548233216.0000 - val_loss: 8258246656.0000\n",
      "Epoch 1287/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7535878656.0000 - val_loss: 8301658624.0000\n",
      "Epoch 1288/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7425573888.0000 - val_loss: 8532858880.0000\n",
      "Epoch 1289/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7435352064.0000 - val_loss: 8561250304.0000\n",
      "Epoch 1290/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7550330368.0000 - val_loss: 8187110400.0000\n",
      "Epoch 1291/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7443298304.0000 - val_loss: 8194556416.0000\n",
      "Epoch 1292/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7627028480.0000 - val_loss: 8425567232.0000\n",
      "Epoch 1293/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7507291136.0000 - val_loss: 8263946752.0000\n",
      "Epoch 1294/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7603278848.0000 - val_loss: 8454622720.0000\n",
      "Epoch 1295/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7458458112.0000 - val_loss: 8309109760.0000\n",
      "Epoch 1296/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7380658176.0000 - val_loss: 8297347072.0000\n",
      "Epoch 1297/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7501188608.0000 - val_loss: 8291352576.0000\n",
      "Epoch 1298/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7458205184.0000 - val_loss: 8162199552.0000\n",
      "Epoch 1299/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7506400768.0000 - val_loss: 8176569856.0000\n",
      "Epoch 1300/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7390537728.0000 - val_loss: 9027531776.0000\n",
      "Epoch 1301/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7619856384.0000 - val_loss: 9462316032.0000\n",
      "Epoch 1302/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7625230848.0000 - val_loss: 8444443136.0000\n",
      "Epoch 1303/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7493627392.0000 - val_loss: 9071912960.0000\n",
      "Epoch 1304/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7476872192.0000 - val_loss: 8170140672.0000\n",
      "Epoch 1305/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7624717824.0000 - val_loss: 8404537344.0000\n",
      "Epoch 1306/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7486936576.0000 - val_loss: 9174334464.0000\n",
      "Epoch 1307/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7574181376.0000 - val_loss: 8552578560.0000\n",
      "Epoch 1308/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7502789120.0000 - val_loss: 8635188224.0000\n",
      "Epoch 1309/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 8054086656.0000 - val_loss: 8218574336.0000\n",
      "Epoch 1310/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7666204160.0000 - val_loss: 8926286848.0000\n",
      "Epoch 1311/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7543496704.0000 - val_loss: 8387677696.0000\n",
      "Epoch 1312/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7425753088.0000 - val_loss: 8646059008.0000\n",
      "Epoch 1313/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7544969728.0000 - val_loss: 8369589760.0000\n",
      "Epoch 1314/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7538339840.0000 - val_loss: 8422094336.0000\n",
      "Epoch 1315/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7527146496.0000 - val_loss: 8261611520.0000\n",
      "Epoch 1316/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7492471808.0000 - val_loss: 8184296448.0000\n",
      "Epoch 1317/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7480383488.0000 - val_loss: 8334499840.0000\n",
      "Epoch 1318/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7446539264.0000 - val_loss: 8439899136.0000\n",
      "Epoch 1319/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7621866496.0000 - val_loss: 8588957696.0000\n",
      "Epoch 1320/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7517361664.0000 - val_loss: 8244359168.0000\n",
      "Epoch 1321/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7568799232.0000 - val_loss: 9504729088.0000\n",
      "Epoch 1322/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7518696960.0000 - val_loss: 8946038784.0000\n",
      "Epoch 1323/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7840747008.0000 - val_loss: 8290850304.0000\n",
      "Epoch 1324/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7489489408.0000 - val_loss: 8325186048.0000\n",
      "Epoch 1325/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7444676608.0000 - val_loss: 8212581888.0000\n",
      "Epoch 1326/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7621437440.0000 - val_loss: 8251233280.0000\n",
      "Epoch 1327/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7410703872.0000 - val_loss: 8225458176.0000\n",
      "Epoch 1328/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7486201344.0000 - val_loss: 8136223744.0000\n",
      "Epoch 1329/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7605690368.0000 - val_loss: 8269822976.0000\n",
      "Epoch 1330/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7300169728.0000 - val_loss: 8621095936.0000\n",
      "Epoch 1331/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7644420608.0000 - val_loss: 8437465600.0000\n",
      "Epoch 1332/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7493828096.0000 - val_loss: 8739239936.0000\n",
      "Epoch 1333/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7541947904.0000 - val_loss: 8514802176.0000\n",
      "Epoch 1334/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7405365248.0000 - val_loss: 8293065728.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1335/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7478420480.0000 - val_loss: 8220678656.0000\n",
      "Epoch 1336/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7467976192.0000 - val_loss: 9241559040.0000\n",
      "Epoch 1337/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7757110272.0000 - val_loss: 8775340032.0000\n",
      "Epoch 1338/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7566257664.0000 - val_loss: 9315828736.0000\n",
      "Epoch 1339/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7557441536.0000 - val_loss: 10270852096.0000\n",
      "Epoch 1340/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7611217920.0000 - val_loss: 8353250816.0000\n",
      "Epoch 1341/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7519680000.0000 - val_loss: 8315134464.0000\n",
      "Epoch 1342/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7381263360.0000 - val_loss: 8354349568.0000\n",
      "Epoch 1343/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7584899072.0000 - val_loss: 8596746240.0000\n",
      "Epoch 1344/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7489639424.0000 - val_loss: 8217641984.0000\n",
      "Epoch 1345/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7479980032.0000 - val_loss: 8146606592.0000\n",
      "Epoch 1346/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7413216256.0000 - val_loss: 8582259712.0000\n",
      "Epoch 1347/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7671055360.0000 - val_loss: 8563415040.0000\n",
      "Epoch 1348/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7608393728.0000 - val_loss: 9268856832.0000\n",
      "Epoch 1349/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7616003072.0000 - val_loss: 8205099520.0000\n",
      "Epoch 1350/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7492989952.0000 - val_loss: 8576717312.0000\n",
      "Epoch 1351/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7501474304.0000 - val_loss: 8510008320.0000\n",
      "Epoch 1352/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7648665600.0000 - val_loss: 8272845312.0000\n",
      "Epoch 1353/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7446220288.0000 - val_loss: 8647333888.0000\n",
      "Epoch 1354/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7390262272.0000 - val_loss: 8338374656.0000\n",
      "Epoch 1355/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7446464512.0000 - val_loss: 8244434944.0000\n",
      "Epoch 1356/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7511152128.0000 - val_loss: 8337187840.0000\n",
      "Epoch 1357/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7363928064.0000 - val_loss: 8344878080.0000\n",
      "Epoch 1358/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7484881408.0000 - val_loss: 8776621056.0000\n",
      "Epoch 1359/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7607061504.0000 - val_loss: 8326211072.0000\n",
      "Epoch 1360/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7541392896.0000 - val_loss: 8643895296.0000\n",
      "Epoch 1361/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7381252608.0000 - val_loss: 8180215808.0000\n",
      "Epoch 1362/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7337798656.0000 - val_loss: 8363905024.0000\n",
      "Epoch 1363/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7513315840.0000 - val_loss: 8385571840.0000\n",
      "Epoch 1364/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7426976768.0000 - val_loss: 8547798528.0000\n",
      "Epoch 1365/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7509741568.0000 - val_loss: 8764744704.0000\n",
      "Epoch 1366/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7543500800.0000 - val_loss: 8418128384.0000\n",
      "Epoch 1367/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7415522304.0000 - val_loss: 8272914432.0000\n",
      "Epoch 1368/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7517271040.0000 - val_loss: 8674174976.0000\n",
      "Epoch 1369/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7471530496.0000 - val_loss: 8202115072.0000\n",
      "Epoch 1370/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7489767424.0000 - val_loss: 8260279296.0000\n",
      "Epoch 1371/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7577645568.0000 - val_loss: 9279397888.0000\n",
      "Epoch 1372/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7465478144.0000 - val_loss: 8433273344.0000\n",
      "Epoch 1373/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7622361088.0000 - val_loss: 8695995392.0000\n",
      "Epoch 1374/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7485481984.0000 - val_loss: 8433712640.0000\n",
      "Epoch 1375/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7451843584.0000 - val_loss: 8472306688.0000\n",
      "Epoch 1376/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7445139456.0000 - val_loss: 8468123648.0000\n",
      "Epoch 1377/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7376496640.0000 - val_loss: 8218868736.0000\n",
      "Epoch 1378/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7452582912.0000 - val_loss: 8413900288.0000\n",
      "Epoch 1379/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7590909440.0000 - val_loss: 8250589696.0000\n",
      "Epoch 1380/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7647623680.0000 - val_loss: 8774049792.0000\n",
      "Epoch 1381/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7436082688.0000 - val_loss: 8681964544.0000\n",
      "Epoch 1382/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7891992576.0000 - val_loss: 9300996096.0000\n",
      "Epoch 1383/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7467114496.0000 - val_loss: 8582692864.0000\n",
      "Epoch 1384/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7464373248.0000 - val_loss: 8713370624.0000\n",
      "Epoch 1385/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500389888.0000 - val_loss: 8231406080.0000\n",
      "Epoch 1386/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7344940032.0000 - val_loss: 8677574656.0000\n",
      "Epoch 1387/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7509326848.0000 - val_loss: 9476631552.0000\n",
      "Epoch 1388/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7552979456.0000 - val_loss: 8456757248.0000\n",
      "Epoch 1389/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7394819584.0000 - val_loss: 8210952704.0000\n",
      "Epoch 1390/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7384061440.0000 - val_loss: 8238782976.0000\n",
      "Epoch 1391/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7518843392.0000 - val_loss: 8219195904.0000\n",
      "Epoch 1392/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500476416.0000 - val_loss: 8504017920.0000\n",
      "Epoch 1393/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7608444928.0000 - val_loss: 8774651904.0000\n",
      "Epoch 1394/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7632572416.0000 - val_loss: 8834885632.0000\n",
      "Epoch 1395/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7442775552.0000 - val_loss: 8286345216.0000\n",
      "Epoch 1396/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7556822016.0000 - val_loss: 8186911744.0000\n",
      "Epoch 1397/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7460494336.0000 - val_loss: 8218779648.0000\n",
      "Epoch 1398/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7494389248.0000 - val_loss: 8254516736.0000\n",
      "Epoch 1399/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7404043776.0000 - val_loss: 8651808768.0000\n",
      "Epoch 1400/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7586697216.0000 - val_loss: 8137907712.0000\n",
      "Epoch 1401/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/119 [==============================] - 0s 3ms/step - loss: 7504623104.0000 - val_loss: 8238024192.0000\n",
      "Epoch 1402/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7504967168.0000 - val_loss: 9728561152.0000\n",
      "Epoch 1403/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7611883520.0000 - val_loss: 8138631168.0000\n",
      "Epoch 1404/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7367909888.0000 - val_loss: 8334519808.0000\n",
      "Epoch 1405/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7494060032.0000 - val_loss: 9084365824.0000\n",
      "Epoch 1406/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7428217856.0000 - val_loss: 8717494272.0000\n",
      "Epoch 1407/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7623625728.0000 - val_loss: 8820499456.0000\n",
      "Epoch 1408/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7474591744.0000 - val_loss: 8131557888.0000\n",
      "Epoch 1409/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7328055808.0000 - val_loss: 8196239360.0000\n",
      "Epoch 1410/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7455238144.0000 - val_loss: 8252103680.0000\n",
      "Epoch 1411/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7462382592.0000 - val_loss: 8131710464.0000\n",
      "Epoch 1412/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7629599744.0000 - val_loss: 8247657984.0000\n",
      "Epoch 1413/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7651620352.0000 - val_loss: 8170963968.0000\n",
      "Epoch 1414/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7409141248.0000 - val_loss: 8274910720.0000\n",
      "Epoch 1415/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7675639808.0000 - val_loss: 8228847616.0000\n",
      "Epoch 1416/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7538806272.0000 - val_loss: 8258855424.0000\n",
      "Epoch 1417/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7457544192.0000 - val_loss: 8646727680.0000\n",
      "Epoch 1418/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7334458880.0000 - val_loss: 8205043712.0000\n",
      "Epoch 1419/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7612192768.0000 - val_loss: 8376709632.0000\n",
      "Epoch 1420/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7485818368.0000 - val_loss: 8870852608.0000\n",
      "Epoch 1421/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7386123776.0000 - val_loss: 8245694464.0000\n",
      "Epoch 1422/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7544034816.0000 - val_loss: 8758264832.0000\n",
      "Epoch 1423/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7555824640.0000 - val_loss: 8195451392.0000\n",
      "Epoch 1424/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7521306624.0000 - val_loss: 8338914304.0000\n",
      "Epoch 1425/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7452660224.0000 - val_loss: 8657065984.0000\n",
      "Epoch 1426/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7600824320.0000 - val_loss: 8188131328.0000\n",
      "Epoch 1427/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7425528832.0000 - val_loss: 8546359808.0000\n",
      "Epoch 1428/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7423083520.0000 - val_loss: 8176660480.0000\n",
      "Epoch 1429/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7389386240.0000 - val_loss: 8447770112.0000\n",
      "Epoch 1430/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7437925888.0000 - val_loss: 8458767360.0000\n",
      "Epoch 1431/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7474702336.0000 - val_loss: 8160607232.0000\n",
      "Epoch 1432/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7485093888.0000 - val_loss: 8423563264.0000\n",
      "Epoch 1433/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7484117504.0000 - val_loss: 8175584256.0000\n",
      "Epoch 1434/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7423065088.0000 - val_loss: 8357730304.0000\n",
      "Epoch 1435/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7529948672.0000 - val_loss: 8787486720.0000\n",
      "Epoch 1436/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7362266624.0000 - val_loss: 8194583040.0000\n",
      "Epoch 1437/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7389300736.0000 - val_loss: 9045465088.0000\n",
      "Epoch 1438/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7500251136.0000 - val_loss: 8154768896.0000\n",
      "Epoch 1439/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7552866304.0000 - val_loss: 8175750144.0000\n",
      "Epoch 1440/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7392452608.0000 - val_loss: 9738431488.0000\n",
      "Epoch 1441/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7591913984.0000 - val_loss: 8155226112.0000\n",
      "Epoch 1442/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7380263936.0000 - val_loss: 8571773952.0000\n",
      "Epoch 1443/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7454721536.0000 - val_loss: 8394940928.0000\n",
      "Epoch 1444/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7563812864.0000 - val_loss: 8496264704.0000\n",
      "Epoch 1445/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7358039552.0000 - val_loss: 8131277312.0000\n",
      "Epoch 1446/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7365532160.0000 - val_loss: 8367402496.0000\n",
      "Epoch 1447/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7424076288.0000 - val_loss: 8137242112.0000\n",
      "Epoch 1448/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7440654336.0000 - val_loss: 8270622208.0000\n",
      "Epoch 1449/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7455506944.0000 - val_loss: 8192493056.0000\n",
      "Epoch 1450/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7469349376.0000 - val_loss: 8246326784.0000\n",
      "Epoch 1451/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7668965376.0000 - val_loss: 8450377728.0000\n",
      "Epoch 1452/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7469901312.0000 - val_loss: 9170650112.0000\n",
      "Epoch 1453/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7428847616.0000 - val_loss: 8176241152.0000\n",
      "Epoch 1454/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7296237056.0000 - val_loss: 8725987328.0000\n",
      "Epoch 1455/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7537061376.0000 - val_loss: 8170540032.0000\n",
      "Epoch 1456/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7436247552.0000 - val_loss: 8419504128.0000\n",
      "Epoch 1457/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7473210368.0000 - val_loss: 8331364864.0000\n",
      "Epoch 1458/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7461023744.0000 - val_loss: 8184610816.0000\n",
      "Epoch 1459/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7426976256.0000 - val_loss: 8191041024.0000\n",
      "Epoch 1460/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7692060160.0000 - val_loss: 8130634240.0000\n",
      "Epoch 1461/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7609163776.0000 - val_loss: 8287150592.0000\n",
      "Epoch 1462/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7646734848.0000 - val_loss: 9825114112.0000\n",
      "Epoch 1463/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7591781376.0000 - val_loss: 8548884992.0000\n",
      "Epoch 1464/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7494394368.0000 - val_loss: 8227431424.0000\n",
      "Epoch 1465/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7432089088.0000 - val_loss: 8762036224.0000\n",
      "Epoch 1466/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7386636800.0000 - val_loss: 8365655552.0000\n",
      "Epoch 1467/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7487753728.0000 - val_loss: 8990886912.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1468/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7507067392.0000 - val_loss: 8967359488.0000\n",
      "Epoch 1469/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7436756480.0000 - val_loss: 8182277632.0000\n",
      "Epoch 1470/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7714510848.0000 - val_loss: 8574618624.0000\n",
      "Epoch 1471/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7373435904.0000 - val_loss: 8439713792.0000\n",
      "Epoch 1472/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7287247872.0000 - val_loss: 8318236672.0000\n",
      "Epoch 1473/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7604989952.0000 - val_loss: 8642007040.0000\n",
      "Epoch 1474/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7449938432.0000 - val_loss: 8228813824.0000\n",
      "Epoch 1475/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7491697152.0000 - val_loss: 8343410688.0000\n",
      "Epoch 1476/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7399906816.0000 - val_loss: 8248358912.0000\n",
      "Epoch 1477/1500\n",
      "119/119 [==============================] - 1s 6ms/step - loss: 7449911296.0000 - val_loss: 8145353216.0000\n",
      "Epoch 1478/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7645218816.0000 - val_loss: 8495471616.0000\n",
      "Epoch 1479/1500\n",
      "119/119 [==============================] - 1s 5ms/step - loss: 7459382272.0000 - val_loss: 8165166592.0000\n",
      "Epoch 1480/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7358685696.0000 - val_loss: 8270074880.0000\n",
      "Epoch 1481/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7321883648.0000 - val_loss: 8179180032.0000\n",
      "Epoch 1482/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7426081792.0000 - val_loss: 8147608064.0000\n",
      "Epoch 1483/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7502012416.0000 - val_loss: 8181596160.0000\n",
      "Epoch 1484/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7466559488.0000 - val_loss: 8153223680.0000\n",
      "Epoch 1485/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7390862336.0000 - val_loss: 8185392640.0000\n",
      "Epoch 1486/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7402289152.0000 - val_loss: 8257355264.0000\n",
      "Epoch 1487/1500\n",
      "119/119 [==============================] - 0s 3ms/step - loss: 7383024640.0000 - val_loss: 8373908480.0000\n",
      "Epoch 1488/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7435241984.0000 - val_loss: 8601633792.0000\n",
      "Epoch 1489/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7323701760.0000 - val_loss: 8225949184.0000\n",
      "Epoch 1490/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7648857600.0000 - val_loss: 8505100800.0000\n",
      "Epoch 1491/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7317161472.0000 - val_loss: 8361803776.0000\n",
      "Epoch 1492/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7443138560.0000 - val_loss: 8217219584.0000\n",
      "Epoch 1493/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7677550080.0000 - val_loss: 8183147520.0000\n",
      "Epoch 1494/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7395381248.0000 - val_loss: 8807681024.0000\n",
      "Epoch 1495/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7691080192.0000 - val_loss: 8201876992.0000\n",
      "Epoch 1496/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7609584640.0000 - val_loss: 8810151936.0000\n",
      "Epoch 1497/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7455555072.0000 - val_loss: 8487822336.0000\n",
      "Epoch 1498/1500\n",
      "119/119 [==============================] - 1s 4ms/step - loss: 7462419456.0000 - val_loss: 8234673152.0000\n",
      "Epoch 1499/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7461761536.0000 - val_loss: 8308205568.0000\n",
      "Epoch 1500/1500\n",
      "119/119 [==============================] - 0s 4ms/step - loss: 7360442880.0000 - val_loss: 8338131968.0000\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 19)                1558      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 19)                380       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,098\n",
      "Trainable params: 3,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=1500,validation_data=(x_test,y_test),batch_size=128,verbose=1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79ace5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9cbcdafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2f76a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595/595 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "tahmin=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9465a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b29a219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167582000576423"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(tahmin,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8edf3b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87089.0950962066"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean_squared_error(tahmin,y))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c00d1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
